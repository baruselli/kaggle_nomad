{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 600, 3000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns={'spacegroup' : 'sg',\n",
    "                            'number_of_total_atoms' : 'Natoms',\n",
    "                            'percent_atom_al' : 'x_Al',\n",
    "                            'percent_atom_ga' : 'x_Ga',\n",
    "                            'percent_atom_in' : 'x_In',\n",
    "                            'lattice_vector_1_ang' : 'a',\n",
    "                            'lattice_vector_2_ang' : 'b',\n",
    "                            'lattice_vector_3_ang' : 'c',\n",
    "                            'lattice_angle_alpha_degree' : 'alpha',\n",
    "                            'lattice_angle_beta_degree' : 'beta',\n",
    "                            'lattice_angle_gamma_degree' : 'gamma',\n",
    "                            'formation_energy_ev_natom' : 'E',\n",
    "                            'bandgap_energy_ev' : 'Eg'}\n",
    "    \n",
    "    \n",
    "df_train = pd.read_csv(\"./input/train.csv\").rename(columns=columns)\n",
    "df_train[\"dataset\"] = \"train\"\n",
    "df_train[\"E\"]=np.log1p(df_train[\"E\"])\n",
    "df_train[\"Eg\"]=np.log1p(df_train[\"Eg\"])\n",
    "df_test = pd.read_csv(\"./input/test.csv\").rename(columns=columns)\n",
    "df_test[\"dataset\"] = \"test\"\n",
    "df_total = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "len(df_train),len(df_test),len(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>Eg</th>\n",
       "      <th>Natoms</th>\n",
       "      <th>a</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>beta</th>\n",
       "      <th>c</th>\n",
       "      <th>dataset</th>\n",
       "      <th>gamma</th>\n",
       "      <th>id</th>\n",
       "      <th>sg</th>\n",
       "      <th>x_Al</th>\n",
       "      <th>x_Ga</th>\n",
       "      <th>x_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065788</td>\n",
       "      <td>1.490362</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.9523</td>\n",
       "      <td>90.0026</td>\n",
       "      <td>8.5513</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>9.1775</td>\n",
       "      <td>train</td>\n",
       "      <td>90.0017</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222343</td>\n",
       "      <td>1.366347</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>90.0186</td>\n",
       "      <td>6.1838</td>\n",
       "      <td>89.9980</td>\n",
       "      <td>23.6287</td>\n",
       "      <td>train</td>\n",
       "      <td>120.0025</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167293</td>\n",
       "      <td>1.320101</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.7510</td>\n",
       "      <td>90.9688</td>\n",
       "      <td>5.6595</td>\n",
       "      <td>91.1228</td>\n",
       "      <td>13.9630</td>\n",
       "      <td>train</td>\n",
       "      <td>30.5185</td>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196553</td>\n",
       "      <td>1.469992</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0036</td>\n",
       "      <td>89.9888</td>\n",
       "      <td>5.0034</td>\n",
       "      <td>90.0119</td>\n",
       "      <td>13.5318</td>\n",
       "      <td>train</td>\n",
       "      <td>120.0017</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.6614</td>\n",
       "      <td>89.9960</td>\n",
       "      <td>6.6612</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>24.5813</td>\n",
       "      <td>train</td>\n",
       "      <td>119.9893</td>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          E        Eg  Natoms       a    alpha       b     beta        c  \\\n",
       "0  0.065788  1.490362    80.0  9.9523  90.0026  8.5513  90.0023   9.1775   \n",
       "1  0.222343  1.366347    80.0  6.1840  90.0186  6.1838  89.9980  23.6287   \n",
       "2  0.167293  1.320101    40.0  9.7510  90.9688  5.6595  91.1228  13.9630   \n",
       "3  0.196553  1.469992    30.0  5.0036  89.9888  5.0034  90.0119  13.5318   \n",
       "4  0.049266  0.866806    80.0  6.6614  89.9960  6.6612  90.0006  24.5813   \n",
       "\n",
       "  dataset     gamma  id   sg    x_Al    x_Ga   x_In  \n",
       "0   train   90.0017   1   33  0.6250  0.3750  0.000  \n",
       "1   train  120.0025   2  194  0.6250  0.3750  0.000  \n",
       "2   train   30.5185   3  227  0.8125  0.1875  0.000  \n",
       "3   train  120.0017   4  167  0.7500  0.0000  0.250  \n",
       "4   train  119.9893   5  194  0.0000  0.6250  0.375  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>Eg</th>\n",
       "      <th>Natoms</th>\n",
       "      <th>a</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>beta</th>\n",
       "      <th>c</th>\n",
       "      <th>dataset</th>\n",
       "      <th>gamma</th>\n",
       "      <th>id</th>\n",
       "      <th>sg</th>\n",
       "      <th>x_Al</th>\n",
       "      <th>x_Ga</th>\n",
       "      <th>x_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.8145</td>\n",
       "      <td>90.0002</td>\n",
       "      <td>6.3964</td>\n",
       "      <td>104.7733</td>\n",
       "      <td>6.2933</td>\n",
       "      <td>test</td>\n",
       "      <td>90.0001</td>\n",
       "      <td>596</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>0.4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.5783</td>\n",
       "      <td>90.0008</td>\n",
       "      <td>9.4849</td>\n",
       "      <td>89.9967</td>\n",
       "      <td>10.1107</td>\n",
       "      <td>test</td>\n",
       "      <td>90.0004</td>\n",
       "      <td>597</td>\n",
       "      <td>33</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.9377</td>\n",
       "      <td>90.0072</td>\n",
       "      <td>6.9372</td>\n",
       "      <td>89.9880</td>\n",
       "      <td>25.0641</td>\n",
       "      <td>test</td>\n",
       "      <td>119.9857</td>\n",
       "      <td>598</td>\n",
       "      <td>194</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.1841</td>\n",
       "      <td>90.0041</td>\n",
       "      <td>8.8659</td>\n",
       "      <td>90.0009</td>\n",
       "      <td>9.4956</td>\n",
       "      <td>test</td>\n",
       "      <td>90.0007</td>\n",
       "      <td>599</td>\n",
       "      <td>33</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.4959</td>\n",
       "      <td>90.0029</td>\n",
       "      <td>9.4956</td>\n",
       "      <td>90.0031</td>\n",
       "      <td>9.4956</td>\n",
       "      <td>test</td>\n",
       "      <td>89.9969</td>\n",
       "      <td>600</td>\n",
       "      <td>206</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.2812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       E  Eg  Natoms        a    alpha       b      beta        c dataset  \\\n",
       "2995 NaN NaN    80.0  24.8145  90.0002  6.3964  104.7733   6.2933    test   \n",
       "2996 NaN NaN    40.0   5.5783  90.0008  9.4849   89.9967  10.1107    test   \n",
       "2997 NaN NaN    80.0   6.9377  90.0072  6.9372   89.9880  25.0641    test   \n",
       "2998 NaN NaN    40.0   5.1841  90.0041  8.8659   90.0009   9.4956    test   \n",
       "2999 NaN NaN    80.0   9.4959  90.0029  9.4956   90.0031   9.4956    test   \n",
       "\n",
       "         gamma   id   sg   x_Al    x_Ga    x_In  \n",
       "2995   90.0001  596   12  0.000  0.5938  0.4062  \n",
       "2996   90.0004  597   33  0.125  0.0000  0.8750  \n",
       "2997  119.9857  598  194  0.000  0.2500  0.7500  \n",
       "2998   90.0007  599   33  0.625  0.0000  0.3750  \n",
       "2999   89.9969  600  206  0.375  0.3438  0.2812  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.kaggle.com/cbartel/random-forest-using-elemental-properties\n",
    "def get_vol(a, b, c, alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        a (float) - lattice vector 1\n",
    "        b (float) - lattice vector 2\n",
    "        c (float) - lattice vector 3\n",
    "        alpha (float) - lattice angle 1 [radians]\n",
    "        beta (float) - lattice angle 2 [radians]\n",
    "        gamma (float) - lattice angle 3 [radians]\n",
    "    Returns:\n",
    "        volume (float) of the parallelepiped unit cell\n",
    "    \"\"\"\n",
    "    alpha=alpha*np.pi/180\n",
    "    beta=beta*np.pi/180\n",
    "    gamma=gamma*np.pi/180\n",
    "    return a*b*c*np.sqrt(1 + 2*np.cos(alpha)*np.cos(beta)*np.cos(gamma)\n",
    "                           - np.cos(alpha)**2\n",
    "                           - np.cos(beta)**2\n",
    "                           - np.cos(gamma)**2)\n",
    "\n",
    "\n",
    "    \n",
    "# compute the cell volumes \n",
    "df_total['vol'] = get_vol(df_total['a'], df_total['b'], df_total['c'],\n",
    "                          df_total['alpha'], df_total['beta'], df_total['gamma'])\n",
    "#df_total[['a','b','c','alpha','beta','gamma','vol']].head()\n",
    "df_total['density']=df_total['Natoms']/df_total[\"vol\"]\n",
    "df_total['density_Al']=df_total['density']*df_total['x_Al']\n",
    "df_total['density_Ga']=df_total['density']*df_total['x_Ga']\n",
    "df_total['density_In']=df_total['density']*df_total['x_In']\n",
    "df_total['sg']=df_total['sg'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>Eg</th>\n",
       "      <th>Natoms</th>\n",
       "      <th>a</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>beta</th>\n",
       "      <th>c</th>\n",
       "      <th>dataset</th>\n",
       "      <th>gamma</th>\n",
       "      <th>id</th>\n",
       "      <th>sg</th>\n",
       "      <th>x_Al</th>\n",
       "      <th>x_Ga</th>\n",
       "      <th>x_In</th>\n",
       "      <th>vol</th>\n",
       "      <th>density</th>\n",
       "      <th>density_Al</th>\n",
       "      <th>density_Ga</th>\n",
       "      <th>density_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065788</td>\n",
       "      <td>1.490362</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.9523</td>\n",
       "      <td>90.0026</td>\n",
       "      <td>8.5513</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>9.1775</td>\n",
       "      <td>train</td>\n",
       "      <td>90.0017</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>781.052081</td>\n",
       "      <td>0.102426</td>\n",
       "      <td>0.064016</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222343</td>\n",
       "      <td>1.366347</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>90.0186</td>\n",
       "      <td>6.1838</td>\n",
       "      <td>89.9980</td>\n",
       "      <td>23.6287</td>\n",
       "      <td>train</td>\n",
       "      <td>120.0025</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>782.500110</td>\n",
       "      <td>0.102236</td>\n",
       "      <td>0.063898</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167293</td>\n",
       "      <td>1.320101</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.7510</td>\n",
       "      <td>90.9688</td>\n",
       "      <td>5.6595</td>\n",
       "      <td>91.1228</td>\n",
       "      <td>13.9630</td>\n",
       "      <td>train</td>\n",
       "      <td>30.5185</td>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>391.227531</td>\n",
       "      <td>0.102242</td>\n",
       "      <td>0.083072</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196553</td>\n",
       "      <td>1.469992</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0036</td>\n",
       "      <td>89.9888</td>\n",
       "      <td>5.0034</td>\n",
       "      <td>90.0119</td>\n",
       "      <td>13.5318</td>\n",
       "      <td>train</td>\n",
       "      <td>120.0017</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>293.377334</td>\n",
       "      <td>0.102257</td>\n",
       "      <td>0.076693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.6614</td>\n",
       "      <td>89.9960</td>\n",
       "      <td>6.6612</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>24.5813</td>\n",
       "      <td>train</td>\n",
       "      <td>119.9893</td>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375</td>\n",
       "      <td>944.713843</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052926</td>\n",
       "      <td>0.031756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          E        Eg  Natoms       a    alpha       b     beta        c  \\\n",
       "0  0.065788  1.490362    80.0  9.9523  90.0026  8.5513  90.0023   9.1775   \n",
       "1  0.222343  1.366347    80.0  6.1840  90.0186  6.1838  89.9980  23.6287   \n",
       "2  0.167293  1.320101    40.0  9.7510  90.9688  5.6595  91.1228  13.9630   \n",
       "3  0.196553  1.469992    30.0  5.0036  89.9888  5.0034  90.0119  13.5318   \n",
       "4  0.049266  0.866806    80.0  6.6614  89.9960  6.6612  90.0006  24.5813   \n",
       "\n",
       "  dataset     gamma  id   sg    x_Al    x_Ga   x_In         vol   density  \\\n",
       "0   train   90.0017   1   33  0.6250  0.3750  0.000  781.052081  0.102426   \n",
       "1   train  120.0025   2  194  0.6250  0.3750  0.000  782.500110  0.102236   \n",
       "2   train   30.5185   3  227  0.8125  0.1875  0.000  391.227531  0.102242   \n",
       "3   train  120.0017   4  167  0.7500  0.0000  0.250  293.377334  0.102257   \n",
       "4   train  119.9893   5  194  0.0000  0.6250  0.375  944.713843  0.084682   \n",
       "\n",
       "   density_Al  density_Ga  density_In  \n",
       "0    0.064016    0.038410    0.000000  \n",
       "1    0.063898    0.038339    0.000000  \n",
       "2    0.083072    0.019170    0.000000  \n",
       "3    0.076693    0.000000    0.025564  \n",
       "4    0.000000    0.052926    0.031756  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pymatgen\n",
    "elem_prop=pd.concat([pd.Series(pymatgen.Element.Al.data,name='Al'), pd.Series(pymatgen.Element.Ga.data,name='Ga'),pd.Series(pymatgen.Element.In.data,name='In')], axis=1)\n",
    "keep=['Atomic mass','Atomic radius','Atomic radius calculated','Density of solid','Ionic radii','Molar volume','Thermal conductivity','Van der waals radius','Velocity of sound','X' ]\n",
    "keep_names=['a_mass','a_radius','a_radius_c','elem_density','ionic_r','molar_v','t_cond','vdw_radius','sound_v','X' ]\n",
    "#keep=['Atomic mass']\n",
    "elem_prop=elem_prop.T\n",
    "elem_prop2=elem_prop[keep]\n",
    "elem_prop2['Ionic radii']=elem_prop2['Ionic radii'].apply(lambda x: (list(x.values()))[0])\n",
    "for c in ['Molar volume','Density of solid','Thermal conductivity','Velocity of sound']:\n",
    "    elem_prop2[c]=elem_prop2[c].apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "for c in   elem_prop2.columns:\n",
    "     elem_prop2[c]=elem_prop2[c].astype(\"float32\")\n",
    "\n",
    "elem_prop2.rename(columns={old:new for (old,new) in zip(keep,keep_names)},inplace=True)\n",
    "\n",
    "print(elem_prop2)\n",
    "\n",
    "def avg_prop(x_Al, x_Ga, x_In, prop):\n",
    "    return elem_prop2.loc['Al',prop]*x_Al+elem_prop2.loc['Ga',prop]*x_Ga+elem_prop2.loc['In',prop]*x_In\n",
    "\n",
    "properties=elem_prop2.columns\n",
    "\n",
    "for prop in properties:\n",
    "    df_total['_'.join(['avg', prop])] = avg_prop(df_train['x_Al'], df_train['x_Ga'],df_train['x_In'],prop)\n",
    "    \n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Encoding of cat features\n",
    "import sys \n",
    "sys.path.append(\"../kaggle_varie\")\n",
    "from  varie import *\n",
    "cols_to_enc=[\"sg\"]\n",
    "\n",
    "#binary encoder\n",
    "#enc=bin_enc(df_total,cols_to_enc,verbose=2,copy=True,drop_original=True,ordinal_only=False)\n",
    "#one-hot encoder\n",
    "enc=pd.get_dummies(df_total,columns=cols_to_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_fct(model,params,df,y_col,n_iter=20,cv=4,drop_col=[],verbose=2):\n",
    "    \n",
    "    X_train=df.drop(y_col+drop_col,axis=1).values\n",
    "    grids=[]\n",
    "    for y in y_col:\n",
    "        print(y)\n",
    "        y_train=df[y].values\n",
    "        print(X_train.shape,y_train.shape)\n",
    "\n",
    "        grid=RandomizedSearchCV(model,param_distributions=params, n_iter=n_iter,cv=cv,verbose=verbose,scoring=\"neg_mean_squared_error\" )\n",
    "\n",
    "        grid.fit(X_train,y_train)\n",
    "        grids.append(grid)\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  ElasticNet\n",
    "ElasticNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cb\n",
      "E\n",
      "(2400, 21) (2400,)\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "[CV] depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   5.0s\n",
      "[CV] depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1187, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   4.9s\n",
      "[CV] depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   6.2s\n",
      "[CV] depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1765, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2, total=   8.4s\n",
      "[CV] depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2, total=   8.4s\n",
      "[CV] depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2, total=   8.0s\n",
      "[CV] depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1927, learning_rate=0.016839702957978098, l2_leaf_reg=2, total=   8.5s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3, total=   2.4s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.05397834017559689, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   6.0s\n",
      "[CV] depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   5.0s\n",
      "[CV] depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1803, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   5.4s\n",
      "[CV] depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   6.1s\n",
      "[CV] depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   6.0s\n",
      "[CV] depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   5.9s\n",
      "[CV] depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1321, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   6.5s\n",
      "[CV] depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   1.2s\n",
      "[CV] depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=166, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   1.2s\n",
      "[CV] depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3, total=   1.5s\n",
      "[CV] depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=409, learning_rate=0.05361687852839719, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.9s\n",
      "[CV] depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1546, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   5.0s\n",
      "[CV] depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=865, learning_rate=0.022188433058710044, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=805, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   3.7s\n",
      "[CV] depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   0.9s\n",
      "[CV] depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   0.7s\n",
      "[CV] depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   0.9s\n",
      "[CV] depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=104, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   1.0s\n",
      "[CV] depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3, total=   3.8s\n",
      "[CV] depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1607, learning_rate=0.09987135664906072, l2_leaf_reg=3, total=   3.8s\n",
      "[CV] depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1398, learning_rate=0.010445739850637821, l2_leaf_reg=3, total=   4.1s\n",
      "[CV] depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   3.1s\n",
      "[CV] depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   3.0s\n",
      "[CV] depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=728, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1839, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.0638016586929384, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   5.6s\n",
      "[CV] depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   5.7s\n",
      "[CV] depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   5.6s\n",
      "[CV] depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1617, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   6.1s\n",
      "[CV] depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   3.7s\n",
      "[CV] depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1339, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1487, learning_rate=0.09958866593165333, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=223, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   1.1s\n",
      "[CV] depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=108, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3, total=   5.3s\n",
      "[CV] depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3, total=   5.3s\n",
      "[CV] depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3, total=   5.3s\n",
      "[CV] depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1550, learning_rate=0.025328934397818307, l2_leaf_reg=3, total=   5.5s\n",
      "[CV] depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3, total=   7.2s\n",
      "[CV] depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3, total=   6.4s\n",
      "[CV] depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=1812, learning_rate=0.016450140352136634, l2_leaf_reg=3, total=   6.2s\n",
      "[CV] depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=490, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   4.0s\n",
      "[CV] depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   4.0s\n",
      "[CV] depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   3.9s\n",
      "[CV] depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1405, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   4.1s\n",
      "[CV] depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2, total=   9.2s\n",
      "[CV] depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2, total=  10.3s\n",
      "[CV] depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2, total=   9.9s\n",
      "[CV] depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1943, learning_rate=0.07697784533374766, l2_leaf_reg=2, total=   9.2s\n",
      "[CV] depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=253, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1190, learning_rate=0.05397834017559689, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2, total=   3.0s\n",
      "[CV] depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1272, learning_rate=0.010344055102905694, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3, total=   1.5s\n",
      "[CV] depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=229, learning_rate=0.026703458933381833, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3, total=   3.8s\n",
      "[CV] depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1798, learning_rate=0.042047531101186496, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=422, learning_rate=0.03180096581918053, l2_leaf_reg=3, total=   2.4s\n",
      "[CV] depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=423, learning_rate=0.042013889722007036, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.5s\n",
      "[CV] depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1483, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.1s\n",
      "[CV] depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=588, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.5s\n",
      "[CV] depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1289, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.7s\n",
      "[CV] depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   9.0s\n",
      "[CV] depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   7.5s\n",
      "[CV] depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   7.0s\n",
      "[CV] depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1994, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   6.7s\n",
      "[CV] depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.1s\n",
      "[CV] depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1140, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   2.6s\n",
      "[CV] depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=893, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2, total=   3.6s\n",
      "[CV] depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2, total=   4.1s\n",
      "[CV] depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=940, learning_rate=0.011501534676964882, l2_leaf_reg=2, total=   3.9s\n",
      "[CV] depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   7.7s\n",
      "[CV] depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   8.6s\n",
      "[CV] depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   8.2s\n",
      "[CV] depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1793, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   8.4s\n",
      "[CV] depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   5.8s\n",
      "[CV] depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1767, learning_rate=0.029683227760220216, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   6.0s\n",
      "[CV] depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   6.0s\n",
      "[CV] depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1264, learning_rate=0.04603906265116819, l2_leaf_reg=2, total=   6.8s\n",
      "[CV] depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   5.0s\n",
      "[CV] depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   5.4s\n",
      "[CV] depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   4.8s\n",
      "[CV] depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1993, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   4.8s\n",
      "[CV] depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3, total=   1.7s\n",
      "[CV] depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=684, learning_rate=0.022427563354281678, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2, total=   3.8s\n",
      "[CV] depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2, total=   3.9s\n",
      "[CV] depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2, total=   4.1s\n",
      "[CV] depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1137, learning_rate=0.09190429786811241, l2_leaf_reg=2, total=   4.0s\n",
      "[CV] depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=546, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.9s\n",
      "[CV] depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   5.9s\n",
      "[CV] depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.1s\n",
      "[CV] depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1623, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   2.4s\n",
      "[CV] depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   2.4s\n",
      "[CV] depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=466, learning_rate=0.01376008342022376, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   1.1s\n",
      "[CV] depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   1.2s\n",
      "[CV] depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=144, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   1.2s\n",
      "[CV] depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=337, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=944, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=772, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   2.2s\n",
      "[CV] depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=959, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1056, learning_rate=0.053139017490043176, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3, total=   6.2s\n",
      "[CV] depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3, total=   6.2s\n",
      "[CV] depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3, total=   6.2s\n",
      "[CV] depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1768, learning_rate=0.011501534676964882, l2_leaf_reg=3, total=   6.3s\n",
      "[CV] depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3, total=   8.0s\n",
      "[CV] depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3, total=   7.3s\n",
      "[CV] depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1925, learning_rate=0.012483952964418074, l2_leaf_reg=3, total=   7.3s\n",
      "[CV] depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2, total=   4.4s\n",
      "[CV] depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2, total=   4.8s\n",
      "[CV] depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1181, learning_rate=0.022064640820967096, l2_leaf_reg=2, total=   4.9s\n",
      "[CV] depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   2.6s\n",
      "[CV] depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=658, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   5.7s\n",
      "[CV] depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   5.3s\n",
      "[CV] depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   5.2s\n",
      "[CV] depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1616, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   5.5s\n",
      "[CV] depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2, total=   2.6s\n",
      "[CV] depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1163, learning_rate=0.03001065603137432, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   3.1s\n",
      "[CV] depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   2.9s\n",
      "[CV] depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1464, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=439, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   1.3s\n",
      "[CV] depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1838, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   3.0s\n",
      "[CV] depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   3.0s\n",
      "[CV] depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=970, learning_rate=0.03124620158992974, l2_leaf_reg=3, total=   3.0s\n",
      "[CV] depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=220, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=744, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   4.7s\n",
      "[CV] depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=890, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3, total=   1.3s\n",
      "[CV] depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=182, learning_rate=0.05522201267844127, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.7s\n",
      "[CV] depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   4.1s\n",
      "[CV] depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=3, iterations=1160, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   5.9s\n",
      "[CV] depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   6.3s\n",
      "[CV] depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1424, learning_rate=0.028513910607754597, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   4.4s\n",
      "[CV] depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   4.5s\n",
      "[CV] depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   4.5s\n",
      "[CV] depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1255, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   4.1s\n",
      "[CV] depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3, total=   7.0s\n",
      "[CV] depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3, total=   6.8s\n",
      "[CV] depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3, total=   7.9s\n",
      "[CV] depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1947, learning_rate=0.03219533616318931, l2_leaf_reg=3, total=   8.1s\n",
      "[CV] depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   3.0s\n",
      "[CV] depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1258, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   2.9s\n",
      "[CV] depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1100, learning_rate=0.06329446631493382, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   4.5s\n",
      "[CV] depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1521, learning_rate=0.031775560054999395, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   4.7s\n",
      "[CV] depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1666, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   4.7s\n",
      "[CV] depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=902, learning_rate=0.028513910607754597, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   4.9s\n",
      "[CV] depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1700, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1971, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   7.6s\n",
      "[CV] depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   8.3s\n",
      "[CV] depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   8.6s\n",
      "[CV] depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1707, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   9.2s\n",
      "[CV] depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   3.0s\n",
      "[CV] depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   2.9s\n",
      "[CV] depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=471, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   2.6s\n",
      "[CV] depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1321, learning_rate=0.06329446631493382, l2_leaf_reg=2, total=   3.1s\n",
      "[CV] depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   2.9s\n",
      "[CV] depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   2.9s\n",
      "[CV] depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=603, learning_rate=0.08005696123070828, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   6.3s\n",
      "[CV] depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1758, learning_rate=0.07028765943266763, l2_leaf_reg=3, total=   6.4s\n",
      "[CV] depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1277, learning_rate=0.03219533616318931, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=986, learning_rate=0.09110552158618711, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   7.4s\n",
      "[CV] depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   6.3s\n",
      "[CV] depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   6.9s\n",
      "[CV] depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1435, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   7.7s\n",
      "[CV] depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1936, learning_rate=0.016752976869181424, l2_leaf_reg=2, total=   4.3s\n",
      "[CV] depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   3.7s\n",
      "[CV] depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   3.7s\n",
      "[CV] depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=645, learning_rate=0.08838773316577991, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=860, learning_rate=0.03001065603137432, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=553, learning_rate=0.03576630849940443, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3, total=   5.2s\n",
      "[CV] depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1633, learning_rate=0.07043396618835486, l2_leaf_reg=3, total=   5.6s\n",
      "[CV] depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   5.7s\n",
      "[CV] depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   5.5s\n",
      "[CV] depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   4.6s\n",
      "[CV] depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1038, learning_rate=0.04750111202621063, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   5.6s\n",
      "[CV] depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   5.2s\n",
      "[CV] depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1125, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=767, learning_rate=0.013829743651345223, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=426, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=304, learning_rate=0.01635839968753775, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2, total=   1.3s\n",
      "[CV] depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2, total=   1.3s\n",
      "[CV] depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=504, learning_rate=0.018016250232357364, l2_leaf_reg=2, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed: 25.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eg\n",
      "(2400, 21) (2400,)\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "[CV] depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2, total=   1.2s\n",
      "[CV] depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2, total=   1.1s\n",
      "[CV] depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2, total=   1.1s\n",
      "[CV] depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=169, learning_rate=0.05522201267844127, l2_leaf_reg=2, total=   1.1s\n",
      "[CV] depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=434, learning_rate=0.034957586726410556, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   5.2s\n",
      "[CV] depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   5.5s\n",
      "[CV] depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1908, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   5.3s\n",
      "[CV] depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2, total=   8.1s\n",
      "[CV] depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2, total=   9.9s\n",
      "[CV] depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2, total=   8.4s\n",
      "[CV] depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1948, learning_rate=0.05291697462388793, l2_leaf_reg=2, total=   7.9s\n",
      "[CV] depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1452, learning_rate=0.016270833266325876, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1852, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=553, learning_rate=0.02606129692865277, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=451, learning_rate=0.03427042590382133, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2, total=   3.9s\n",
      "[CV] depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2, total=   3.7s\n",
      "[CV] depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1100, learning_rate=0.034957586726410556, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   3.0s\n",
      "[CV] depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1304, learning_rate=0.046776419929082796, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=415, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   4.8s\n",
      "[CV] depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   4.7s\n",
      "[CV] depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1961, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   5.4s\n",
      "[CV] depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   1.1s\n",
      "[CV] depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=131, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1221, learning_rate=0.023339334540071897, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   8.4s\n",
      "[CV] depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   8.6s\n",
      "[CV] depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   8.8s\n",
      "[CV] depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1904, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   9.1s\n",
      "[CV] depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3, total=   2.6s\n",
      "[CV] depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=757, learning_rate=0.0949738656118928, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   4.9s\n",
      "[CV] depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1313, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   6.5s\n",
      "[CV] depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1886, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1531, learning_rate=0.016270833266325876, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2, total=   3.6s\n",
      "[CV] depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2, total=   4.6s\n",
      "[CV] depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2, total=   4.2s\n",
      "[CV] depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1646, learning_rate=0.022188433058710044, l2_leaf_reg=2, total=   3.8s\n",
      "[CV] depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=900, learning_rate=0.023339334540071897, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=548, learning_rate=0.015200311002038338, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   3.7s\n",
      "[CV] depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1222, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   3.6s\n",
      "[CV] depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   5.9s\n",
      "[CV] depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   6.2s\n",
      "[CV] depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   5.9s\n",
      "[CV] depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=1781, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   6.7s\n",
      "[CV] depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   4.7s\n",
      "[CV] depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   4.9s\n",
      "[CV] depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1660, learning_rate=0.04454012172413003, l2_leaf_reg=2, total=   4.7s\n",
      "[CV] depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   1.5s\n",
      "[CV] depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   1.5s\n",
      "[CV] depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=439, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   1.5s\n",
      "[CV] depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=427, learning_rate=0.0774875600906035, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   1.7s\n",
      "[CV] depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   1.7s\n",
      "[CV] depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=343, learning_rate=0.01583042064951216, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3, total=   1.0s\n",
      "[CV] depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3, total=   1.0s\n",
      "[CV] depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3, total=   0.9s\n",
      "[CV] depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=114, learning_rate=0.09087030112017504, l2_leaf_reg=3, total=   0.9s\n",
      "[CV] depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   3.6s\n",
      "[CV] depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   3.8s\n",
      "[CV] depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   4.1s\n",
      "[CV] depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1871, learning_rate=0.01781222232172585, l2_leaf_reg=2, total=   3.7s\n",
      "[CV] depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=399, learning_rate=0.0431440862207052, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   0.9s\n",
      "[CV] depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   1.3s\n",
      "[CV] depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=178, learning_rate=0.08838773316577991, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   6.6s\n",
      "[CV] depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   7.1s\n",
      "[CV] depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   7.0s\n",
      "[CV] depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1762, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   7.9s\n",
      "[CV] depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3, total=   3.8s\n",
      "[CV] depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=657, learning_rate=0.09947925011898447, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   4.8s\n",
      "[CV] depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   4.9s\n",
      "[CV] depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   5.2s\n",
      "[CV] depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1843, learning_rate=0.06372449985643683, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   5.8s\n",
      "[CV] depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   5.5s\n",
      "[CV] depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1898, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   6.1s\n",
      "[CV] depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2, total=   2.6s\n",
      "[CV] depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=933, learning_rate=0.025328934397818307, l2_leaf_reg=2, total=   2.4s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1145, learning_rate=0.02321467054907231, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1119, learning_rate=0.010344055102905694, l2_leaf_reg=3, total=   2.8s\n",
      "[CV] depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   5.8s\n",
      "[CV] depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   6.3s\n",
      "[CV] depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   6.4s\n",
      "[CV] depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1660, learning_rate=0.046776419929082796, l2_leaf_reg=3, total=   6.1s\n",
      "[CV] depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2, total=   3.9s\n",
      "[CV] depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2, total=   4.0s\n",
      "[CV] depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=935, learning_rate=0.07560125064474257, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=990, learning_rate=0.07242175416325623, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   1.7s\n",
      "[CV] depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   1.6s\n",
      "[CV] depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=558, learning_rate=0.02294725413319747, l2_leaf_reg=3, total=   1.7s\n",
      "[CV] depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=773, learning_rate=0.03501894839349694, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3, total=   6.1s\n",
      "[CV] depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3, total=   7.5s\n",
      "[CV] depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3, total=   6.8s\n",
      "[CV] depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1711, learning_rate=0.07962082412943851, l2_leaf_reg=3, total=   6.4s\n",
      "[CV] depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   2.2s\n",
      "[CV] depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=386, learning_rate=0.09947925011898447, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   5.2s\n",
      "[CV] depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1196, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1068, learning_rate=0.038507684913374814, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1658, learning_rate=0.033122277555893226, l2_leaf_reg=3, total=   4.2s\n",
      "[CV] depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2, total=   4.8s\n",
      "[CV] depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2, total=   4.6s\n",
      "[CV] depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2, total=   4.6s\n",
      "[CV] depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1591, learning_rate=0.04087395289764893, l2_leaf_reg=2, total=   4.7s\n",
      "[CV] depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3, total=   1.0s\n",
      "[CV] depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=237, learning_rate=0.04050726109485145, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3, total=   3.3s\n",
      "[CV] depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1827, learning_rate=0.08795015841495676, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   1.2s\n",
      "[CV] depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=217, learning_rate=0.019910900138693486, l2_leaf_reg=3, total=   1.3s\n",
      "[CV] depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=836, learning_rate=0.026703458933381833, l2_leaf_reg=2, total=   3.1s\n",
      "[CV] depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   6.4s\n",
      "[CV] depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   6.3s\n",
      "[CV] depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   5.8s\n",
      "[CV] depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1204, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   5.7s\n",
      "[CV] depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2, total=   2.8s\n",
      "[CV] depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=547, learning_rate=0.013829743651345223, l2_leaf_reg=2, total=   2.9s\n",
      "[CV] depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   6.8s\n",
      "[CV] depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   6.5s\n",
      "[CV] depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   7.0s\n",
      "[CV] depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=1550, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   7.3s\n",
      "[CV] depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   6.9s\n",
      "[CV] depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   7.0s\n",
      "[CV] depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   6.6s\n",
      "[CV] depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1453, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   5.7s\n",
      "[CV] depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   3.5s\n",
      "[CV] depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   3.4s\n",
      "[CV] depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1067, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=925, learning_rate=0.029683227760220216, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2, total=   3.8s\n",
      "[CV] depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2, total=   3.2s\n",
      "[CV] depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2, total=   3.1s\n",
      "[CV] depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1003, learning_rate=0.031775560054999395, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=359, learning_rate=0.042047531101186496, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   1.3s\n",
      "[CV] depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=405, learning_rate=0.07242175416325623, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   3.4s\n",
      "[CV] depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   3.5s\n",
      "[CV] depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=1880, learning_rate=0.08625258753800176, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3, total=   4.9s\n",
      "[CV] depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1440, learning_rate=0.07697784533374766, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   1.3s\n",
      "[CV] depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   1.3s\n",
      "[CV] depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   1.3s\n",
      "[CV] depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=289, learning_rate=0.012883053900308314, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2, total=   5.3s\n",
      "[CV] depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2, total=   5.4s\n",
      "[CV] depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2, total=   6.1s\n",
      "[CV] depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1868, learning_rate=0.07962082412943851, l2_leaf_reg=2, total=   5.6s\n",
      "[CV] depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.4s\n",
      "[CV] depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.2s\n",
      "[CV] depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.3s\n",
      "[CV] depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1829, learning_rate=0.02194900195958145, l2_leaf_reg=3, total=   6.3s\n",
      "[CV] depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1316, learning_rate=0.0576875549158209, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1743, learning_rate=0.04454012172413003, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3, total=   3.7s\n",
      "[CV] depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3, total=   2.9s\n",
      "[CV] depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=781, learning_rate=0.08625258753800176, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   1.0s\n",
      "[CV] depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   0.9s\n",
      "[CV] depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=236, learning_rate=0.022761243586365002, l2_leaf_reg=2, total=   0.9s\n",
      "[CV] depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   4.8s\n",
      "[CV] depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   5.0s\n",
      "[CV] depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   4.7s\n",
      "[CV] depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1348, learning_rate=0.0932220847391707, l2_leaf_reg=2, total=   4.7s\n",
      "[CV] depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3, total=   1.4s\n",
      "[CV] depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=166, learning_rate=0.03576630849940443, l2_leaf_reg=3, total=   1.1s\n",
      "[CV] depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   4.9s\n",
      "[CV] depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   6.0s\n",
      "[CV] depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=3, iterations=1794, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   6.3s\n",
      "[CV] depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   3.0s\n",
      "[CV] depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   2.5s\n",
      "[CV] depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=1004, learning_rate=0.038507684913374814, l2_leaf_reg=2, total=   2.7s\n",
      "[CV] depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2, total=   2.2s\n",
      "[CV] depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=696, learning_rate=0.0443431204452299, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=911, learning_rate=0.08795015841495676, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=963, learning_rate=0.016752976869181424, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=838, learning_rate=0.03465140637006451, l2_leaf_reg=2, total=   1.9s\n",
      "[CV] depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=891, learning_rate=0.01583042064951216, l2_leaf_reg=2, total=   3.8s\n",
      "[CV] depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=647, learning_rate=0.07750573625234321, l2_leaf_reg=2, total=   2.0s\n",
      "[CV] depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2, total=   5.1s\n",
      "[CV] depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2, total=   4.7s\n",
      "[CV] depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2, total=   4.6s\n",
      "[CV] depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=1221, learning_rate=0.017424851332484684, l2_leaf_reg=2, total=   4.5s\n",
      "[CV] depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   3.1s\n",
      "[CV] depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1040, learning_rate=0.04684581468329573, l2_leaf_reg=3, total=   3.2s\n",
      "[CV] depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=1190, learning_rate=0.023276890247597416, l2_leaf_reg=3, total=   4.9s\n",
      "[CV] depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   4.0s\n",
      "[CV] depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   3.9s\n",
      "[CV] depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1720, learning_rate=0.07750573625234321, l2_leaf_reg=3, total=   4.6s\n",
      "[CV] depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3, total=   2.2s\n",
      "[CV] depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=534, learning_rate=0.0638887684122254, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=249, learning_rate=0.019910900138693486, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   2.6s\n",
      "[CV] depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3 \n",
      "[CV]  depth=2, iterations=1077, learning_rate=0.015200311002038338, l2_leaf_reg=3, total=   2.7s\n",
      "[CV] depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   1.8s\n",
      "[CV] depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   1.9s\n",
      "[CV] depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=527, learning_rate=0.04874577557339601, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2, total=   1.7s\n",
      "[CV] depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2 \n",
      "[CV]  depth=1, iterations=780, learning_rate=0.024067385136911725, l2_leaf_reg=2, total=   1.8s\n",
      "[CV] depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   2.1s\n",
      "[CV] depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2 \n",
      "[CV]  depth=4, iterations=502, learning_rate=0.017992186658304845, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2, total=   3.3s\n",
      "[CV] depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2, total=   3.1s\n",
      "[CV] depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2, total=   3.8s\n",
      "[CV] depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2 \n",
      "[CV]  depth=5, iterations=686, learning_rate=0.0638887684122254, l2_leaf_reg=2, total=   3.9s\n",
      "[CV] depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2, total=   1.5s\n",
      "[CV] depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2, total=   1.4s\n",
      "[CV] depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2, total=   1.6s\n",
      "[CV] depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=386, learning_rate=0.07043396618835486, l2_leaf_reg=2, total=   1.3s\n",
      "[CV] depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   5.6s\n",
      "[CV] depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   5.3s\n",
      "[CV] depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   5.5s\n",
      "[CV] depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3 \n",
      "[CV]  depth=3, iterations=1920, learning_rate=0.03465140637006451, l2_leaf_reg=3, total=   5.2s\n",
      "[CV] depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   2.0s\n",
      "[CV] depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3 \n",
      "[CV]  depth=5, iterations=366, learning_rate=0.017424851332484684, l2_leaf_reg=3, total=   2.1s\n",
      "[CV] depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2, total=   2.3s\n",
      "[CV] depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2, total=   2.2s\n",
      "[CV] depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2 \n",
      "[CV]  depth=2, iterations=867, learning_rate=0.0638016586929384, l2_leaf_reg=2, total=   2.2s\n",
      "[CV] depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3, total=   2.4s\n",
      "[CV] depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3, total=   2.3s\n",
      "[CV] depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3 \n",
      "[CV]  depth=1, iterations=1186, learning_rate=0.08055724926451685, l2_leaf_reg=3, total=   2.5s\n",
      "[CV] depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   6.8s\n",
      "[CV] depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   6.5s\n",
      "[CV] depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   7.4s\n",
      "[CV] depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1786, learning_rate=0.023496629940717384, l2_leaf_reg=3, total=   6.9s\n",
      "[CV] depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   4.4s\n",
      "[CV] depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   4.3s\n",
      "[CV] depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   5.1s\n",
      "[CV] depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3 \n",
      "[CV]  depth=4, iterations=1191, learning_rate=0.018016250232357364, l2_leaf_reg=3, total=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed: 23.0min finished\n"
     ]
    }
   ],
   "source": [
    "#grid search for random forest\n",
    "import scipy\n",
    "from  sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import *\n",
    "from catboost import CatBoostRegressor,CatBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import  ElasticNet\n",
    "from sklearn.ensemble import  GradientBoostingRegressor, RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.kernel_approximation import Nystroem\n",
    "#from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from xgboost import XGBRegressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "from varie import lognuniform\n",
    "from varie import loguniform2\n",
    "%aimport varie\n",
    "\n",
    "y_col=[\"E\",\"Eg\"]\n",
    "drop_col=[\"id\",\"dataset\"]\n",
    "df_total_train_eval=enc[df_total.dataset=='train']\n",
    "df_total_test=enc[df_total.dataset=='test']\n",
    "\n",
    "X_train=df_total_train_eval.drop(y_col+drop_col,axis=1).values\n",
    "X_test=df_total_test.drop(y_col+drop_col,axis=1).values\n",
    "\n",
    "models={\n",
    "    \n",
    "    'knn':\n",
    "           (KNeighborsRegressor(),\n",
    "            {'n_neighbors':scipy.stats.randint(1,100)}),\n",
    "    \n",
    "    'svr':\n",
    "           (SVR(verbose=False),\n",
    "            {'C':loguniform(low=-4,high=4,base=10,size=100),\n",
    "                'epsilon':lognuniform(low=-2,high=0,base=10,size=100)}),\n",
    "\n",
    "    'rf':\n",
    "           (ensemble.RandomForestRegressor(verbose=False),\n",
    "            {\"max_depth\": scipy.stats.randint(1,100), \n",
    "             'n_estimators': scipy.stats.randint(1,400),\n",
    "             'max_features':('log2','sqrt','auto'),\n",
    "             'min_samples_split':scipy.stats.randint(2,5),\n",
    "             'min_samples_leaf':scipy.stats.randint(1,5)}),\n",
    "    \n",
    "    'cb':\n",
    "           (CatBoostRegressor(loss_function='RMSE', eval_metric='RMSE',logging_level='Silent'),\n",
    "            {\"depth\": scipy.stats.randint(1,6), \n",
    "             'iterations': scipy.stats.randint(100,2000),\n",
    "             'learning_rate':lognuniform(low=-2,high=-1,base=10,size=100),\n",
    "             'l2_leaf_reg': scipy.stats.randint(2,4)}),\n",
    "    \n",
    "    'mlp': \n",
    "           (MLPRegressor((80, 10), early_stopping=False),\n",
    "             {'hidden_layer_sizes':scipy.stats.randint(1,100),\n",
    "              'alpha':lognuniform(low=-5,high=-1,base=10,size=100)}),\n",
    "             \n",
    "     'gb':\n",
    "           (GradientBoostingRegressor(n_estimators=100),\n",
    "            {'learning_rate':lognuniform(low=-3,high=-1,base=10,size=100), \n",
    "             'n_estimators': scipy.stats.randint(1,300),\n",
    "             'max_depth':scipy.stats.randint(1,5),\n",
    "             'max_features':('sqrt','log2','auto')}),\n",
    "    \n",
    "    'lasso':\n",
    "            (Lasso(),\n",
    "            {'alpha':lognuniform(low=-6,high=2,base=10,size=100)}),  \n",
    "\n",
    "    'ridge':\n",
    "            (Ridge(),\n",
    "            {'alpha':varie.lognuniform(low=-6,high=2,base=10,size=100)}),\n",
    "    \n",
    "    'eln':\n",
    "            (ElasticNet(),\n",
    "            {'alpha':lognuniform(low=-6,high=4,base=10,size=100), \n",
    "             'l1_ratio':lognuniform(low=-6,high=4,base=10,size=100)}),\n",
    "    \n",
    "    'xgb':\n",
    "        (XGBRegressor(),\n",
    "         {'max_depth':scipy.stats.randint(1,100), \n",
    "          'learning_rate':lognuniform(low=-4,high=-0.5,base=10,size=100), \n",
    "          'n_estimators':scipy.stats.randint(1,400),\n",
    "          'colsample_bytree': uniform(0.55, 0.66),\n",
    "          'min_child_weight': randint(30, 60),\n",
    "          'colsample_bytree': uniform(0.6, 0.4),\n",
    "          'reg_lambda': uniform(1, 2),\n",
    "          'reg_alpha': uniform(1, 2),\n",
    "}),\n",
    "    \n",
    " #does not install    \n",
    " #   'gbm' :\n",
    " #       (lgb.LGBMRegressor(objective='regression'),\n",
    " #           {'num_leaves':scipy.stats.randint(1,200), \n",
    " #         'learning_rate':lognuniform(low=-4,high=-0.5,base=10,size=100), \n",
    " #         'n_estimators':scipy.stats.randint(1,400)}),\n",
    "    'adb' :\n",
    "        (AdaBoostRegressor(loss=\"square\"),\n",
    "            {'learning_rate':lognuniform(low=-4,high=-0.1,base=10,size=100), \n",
    "             'n_estimators':scipy.stats.randint(1,400)}),         \n",
    "\n",
    "    \n",
    "       }\n",
    " \n",
    "    \n",
    "\n",
    "try:\n",
    "    results\n",
    "except:\n",
    "    results={}\n",
    "    \n",
    "for (tag,model) in  models.items():\n",
    "    if (tag not in results):\n",
    "        print(tag)\n",
    "        results[tag]=grid_search_fct(model[0],model[1],df_total_train_eval,y_col,n_iter=100,cv=4,drop_col=drop_col)\n",
    "\n",
    "\n",
    "    \n",
    "    #grid=RandomizedSearchCV(model[0],param_distributions=params, n_iter=20,cv=4,verbose=2,scoring=\"neg_mean_squared_error\" )\n",
    "\n",
    "                        \n",
    "    #grid.fit(X_train,y_train)\n",
    "    #grids.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomizedSearchCV(cv=4, error_score='raise',\n",
       "           estimator=<catboost.core.CatBoostRegressor object at 0x7ff018b4c3c8>,\n",
       "           fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "           param_distributions={'depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff018b4c4a8>, 'iterations': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff018b4c588>, 'learning_rate': array([0.06793, 0.02726, ..., 0.01334, 0.01936])},\n",
       "           pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "           return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "           verbose=2), RandomizedSearchCV(cv=4, error_score='raise',\n",
       "           estimator=<catboost.core.CatBoostRegressor object at 0x7ff018b4c3c8>,\n",
       "           fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "           param_distributions={'depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff018b4c4a8>, 'iterations': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff018b4c588>, 'learning_rate': array([0.06793, 0.02726, ..., 0.01334, 0.01936])},\n",
       "           pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "           return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "           verbose=2)]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#pickle.dump(results, open( \"results_100iter.pickle\", \"wb\" ))\n",
    "#results.pop('cb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb\n",
      "{'min_child_weight': 50, 'max_depth': 20, 'reg_alpha': 1.073947179242888, 'colsample_bytree': 0.9495387910705909, 'n_estimators': 82, 'learning_rate': 0.19564220615889624, 'reg_lambda': 2.5750775958117913}\n",
      "{'min_child_weight': 59, 'max_depth': 47, 'reg_alpha': 1.0745756197034326, 'colsample_bytree': 0.894792479949726, 'n_estimators': 394, 'learning_rate': 0.021394988524502393, 'reg_lambda': 1.4038745160788761}\n",
      "0.06070531708533062\n",
      "svr\n",
      "{'C': 7.714813468681621, 'epsilon': 0.019583331445081988}\n",
      "{'C': 0.3418951606057705, 'epsilon': 0.02841600304754715}\n",
      "0.094502440393147\n",
      "mlp\n",
      "{'alpha': 0.013697209704446447, 'hidden_layer_sizes': 98}\n",
      "{'alpha': 1.2764744090326039e-05, 'hidden_layer_sizes': 98}\n",
      "0.1470021188220108\n",
      "rf\n",
      "{'max_features': 'log2', 'max_depth': 9, 'n_estimators': 267}\n",
      "{'max_features': 'sqrt', 'max_depth': 8, 'n_estimators': 336}\n",
      "0.06256737960363293\n",
      "ridge\n",
      "{'alpha': 0.0003364106604226533}\n",
      "{'alpha': 0.0005566509619678715}\n",
      "0.06670031387253723\n",
      "knn\n",
      "{'n_neighbors': 5}\n",
      "{'n_neighbors': 3}\n",
      "0.08328574574301126\n",
      "eln\n",
      "{'l1_ratio': 0.002876728860010476, 'alpha': 1.116443095831075e-06}\n",
      "{'l1_ratio': 0.14465909996223247, 'alpha': 1.0571211597903444e-06}\n",
      "0.0667836117024544\n",
      "gb\n",
      "{'max_features': 'log2', 'learning_rate': 0.031239955884344705, 'max_depth': 4, 'n_estimators': 284}\n",
      "{'max_features': 'sqrt', 'learning_rate': 0.04767184227679692, 'max_depth': 4, 'n_estimators': 144}\n",
      "0.06066055720876712\n",
      "cb\n",
      "{'depth': 5, 'iterations': 1435, 'learning_rate': 0.016270833266325876, 'l2_leaf_reg': 3}\n",
      "{'depth': 3, 'iterations': 1040, 'learning_rate': 0.04684581468329573, 'l2_leaf_reg': 3}\n",
      "0.05905833280659943\n",
      "lasso\n",
      "{'alpha': 2.1395325752545475e-06}\n",
      "{'alpha': 2.1395325752545475e-06}\n",
      "0.06672046289641745\n",
      "adb\n",
      "{'learning_rate': 0.13761901851857872, 'n_estimators': 211}\n",
      "{'learning_rate': 0.1275450652005196, 'n_estimators': 38}\n",
      "0.07931976061778094\n"
     ]
    }
   ],
   "source": [
    "#best models and their performance\n",
    "\n",
    "for tag,grids in results.items():\n",
    "    print(tag)\n",
    "    for grid in grids:\n",
    "        print(grid.best_params_)\n",
    "    print((np.sqrt(-grids[0].best_score_)+np.sqrt(-grids[1].best_score_))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "        learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "        min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "        objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "        scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       " {'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefee4885c0>,\n",
       "  'learning_rate': array([8.51449911e-03, 5.11998252e-02, 1.65751975e-01, 5.45008940e-02,\n",
       "         2.36368993e-01, 6.05695533e-04, 2.66160637e-03, 2.85826030e-03,\n",
       "         6.39575488e-04, 2.49487140e-03, 3.08001078e-03, 1.34662552e-03,\n",
       "         4.22702713e-02, 1.70922580e-02, 2.23401003e-01, 1.07362617e-02,\n",
       "         1.20987221e-04, 1.33759572e-03, 3.73324526e-02, 8.24032738e-04,\n",
       "         2.30313264e-02, 1.30357543e-01, 1.13102410e-03, 1.81017102e-03,\n",
       "         1.68583754e-04, 4.32220730e-03, 1.32185029e-04, 2.51015261e-01,\n",
       "         1.52757643e-01, 1.07889541e-01, 5.91861241e-04, 2.49474470e-01,\n",
       "         1.19240753e-01, 6.84111193e-02, 8.04654327e-02, 2.56613192e-03,\n",
       "         8.75391740e-03, 7.04062196e-04, 1.92001958e-04, 4.69736948e-03,\n",
       "         8.16347848e-03, 9.86901269e-04, 5.89526683e-02, 2.18550654e-03,\n",
       "         1.02745375e-02, 3.61128785e-03, 4.05447310e-03, 2.37250869e-02,\n",
       "         1.30677155e-03, 2.22710061e-03, 4.51085035e-02, 6.69250796e-04,\n",
       "         3.24068522e-02, 5.83305644e-02, 4.39592921e-03, 1.23359972e-02,\n",
       "         2.75119479e-02, 2.89235380e-04, 1.91031248e-01, 3.57692675e-03,\n",
       "         5.89809480e-04, 5.26830802e-02, 1.48460618e-01, 1.14258145e-01,\n",
       "         2.28597358e-01, 5.86871847e-02, 6.88374823e-02, 1.45315636e-01,\n",
       "         2.32927322e-03, 1.87830644e-03, 1.46499805e-04, 1.38610235e-02,\n",
       "         9.88139982e-02, 1.67490960e-02, 3.36287358e-04, 7.53946929e-03,\n",
       "         5.04822170e-02, 8.96363864e-04, 2.76272629e-02, 1.74394624e-03,\n",
       "         4.56560153e-04, 8.33045930e-04, 2.03677860e-04, 5.11823370e-02,\n",
       "         2.28635285e-04, 9.46689991e-04, 2.91057926e-01, 3.86118204e-03,\n",
       "         3.19565078e-03, 1.14223186e-04, 4.06251295e-02, 1.60736167e-02,\n",
       "         2.87773681e-01, 2.33676300e-04, 2.99855106e-01, 7.98220824e-04,\n",
       "         4.43438570e-03, 4.68516078e-04, 1.39615531e-04, 1.94153272e-03]),\n",
       "  'max_depth': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefee481ef0>,\n",
       "  'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefee488860>,\n",
       "  'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefee4880b8>,\n",
       "  'reg_alpha': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefee488da0>,\n",
       "  'reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefee488be0>})"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBRegressor(base_score=0.5, colsample_bylevel=1,\n",
       "        colsample_bytree=0.9495387910705909, gamma=0,\n",
       "        learning_rate=0.19564220615889624, max_delta_step=0, max_depth=20,\n",
       "        min_child_weight=50, missing=None, n_estimators=82, nthread=-1,\n",
       "        objective='reg:linear', reg_alpha=1.073947179242888,\n",
       "        reg_lambda=2.5750775958117913, scale_pos_weight=1, seed=0,\n",
       "        silent=True, subsample=1),\n",
       " SVR(C=7.714813468681621, cache_size=200, coef0=0.0, degree=3,\n",
       "   epsilon=0.019583331445081988, gamma='auto', kernel='rbf', max_iter=-1,\n",
       "   shrinking=True, tol=0.001, verbose=False),\n",
       " MLPRegressor(activation='relu', alpha=0.013697209704446447, batch_size='auto',\n",
       "        beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=98, learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=9,\n",
       "            max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=267, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=False,\n",
       "            warm_start=False),\n",
       " Ridge(alpha=0.0003364106604226533, copy_X=True, fit_intercept=True,\n",
       "    max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "    tol=0.001),\n",
       " KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       " ElasticNet(alpha=1.116443095831075e-06, copy_X=True, fit_intercept=True,\n",
       "       l1_ratio=0.002876728860010476, max_iter=1000, normalize=False,\n",
       "       positive=False, precompute=False, random_state=None,\n",
       "       selection='cyclic', tol=0.0001, warm_start=False),\n",
       " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.031239955884344705, loss='ls', max_depth=4,\n",
       "              max_features='log2', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=284,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       " <catboost.core.CatBoostRegressor at 0x7fefee4c2f98>,\n",
       " Lasso(alpha=2.1395325752545475e-06, copy_X=True, fit_intercept=True,\n",
       "    max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "    random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " AdaBoostRegressor(base_estimator=None, learning_rate=0.13761901851857872,\n",
       "          loss='square', n_estimators=211, random_state=None)]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learners1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter meta-Cat for estimator StackingRegressor(meta_regressor=<catboost.core.CatBoostRegressor object at 0x7fefee38a470>,\n         regressors=[XGBRegressor(base_score=0.5, colsample_bylevel=1,\n       colsample_bytree=0.9495387910705909, gamma=0,\n       learning_rate=0.19564220615889624, max_delta_step=0, max_depth=20,\n       min_child_weight=50, missing=None, n_estimators=82, nthread=-1,\n       objective='reg:linear', reg_alpha...ne, learning_rate=0.13761901851857872,\n         loss='square', n_estimators=211, random_state=None)],\n         store_train_meta_features=False, verbose=0). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-526038f43591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_total_train_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mresults2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter meta-Cat for estimator StackingRegressor(meta_regressor=<catboost.core.CatBoostRegressor object at 0x7fefee38a470>,\n         regressors=[XGBRegressor(base_score=0.5, colsample_bylevel=1,\n       colsample_bytree=0.9495387910705909, gamma=0,\n       learning_rate=0.19564220615889624, max_delta_step=0, max_depth=20,\n       min_child_weight=50, missing=None, n_estimators=82, nthread=-1,\n       objective='reg:linear', reg_alpha...ne, learning_rate=0.13761901851857872,\n         loss='square', n_estimators=211, random_state=None)],\n         store_train_meta_features=False, verbose=0). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "meta_learner=CatBoostRegressor(loss_function='RMSE', eval_metric='RMSE',logging_level='Silent')\n",
    "\n",
    "params_meta={'meta-me__depth': scipy.stats.randint(1,6)}\n",
    "             \n",
    "             \n",
    "             #'meta-meta_learner__iterations': scipy.stats.randint(100,2000),\n",
    "             #'meta-meta_learner__learning_rate':lognuniform(low=-2,high=-1,base=10,size=100),\n",
    "             #'meta-meta_learner__l2_leaf_reg': scipy.stats.randint(2,4)}\n",
    "            \n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "learners1=[g[0].best_estimator_ for g in results.values()]\n",
    "learners2=[g[1].best_estimator_ for g in results.values()]\n",
    "learners=[learners1,learners2]\n",
    "\n",
    "stregr = [StackingRegressor(regressors=learners1,meta_regressor=meta_learner),\n",
    "          StackingRegressor(regressors=learners2,meta_regressor=meta_learner)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results2={}\n",
    "for s,y in zip(stregr,y_col):\n",
    "    #print(s,y)\n",
    "    y_train=df_total_train_eval[y]\n",
    "    grid=RandomizedSearchCV(s,param_distributions=params_meta, n_iter=10,cv=5,verbose=1,scoring=\"neg_mean_squared_error\" )\n",
    "    grid.fit(X_train, y_train)\n",
    "    results2.append(grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "(2400, 21) (2400,)\n",
      "\n",
      "Fitting 2 layers\n"
     ]
    },
    {
     "ename": "JoblibIndexError",
     "evalue": "JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 16, 0, 7, 95325), 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2CB284014A464058AFF9C38F92506A27']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 16, 0, 7, 95325), 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2CB284014A464058AFF9C38F92506A27'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 16, 0, 7, 95325), 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-329-7aeec184221c>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fefe41d5b38, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fefeecc5a50, file \"<ipython-input-329-7aeec184221c>\", line 50>\n        result = <ExecutionResult object at 7fefe41d5b38, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fefeecc5a50, file \"<ipython-input-329-7aeec184221c>\", line 50>, result=<ExecutionResult object at 7fefe41d5b38, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fefeecc5a50, file \"<ipython-input-329-7aeec184221c>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/scratch/baruselli/kaggle_nomad/<ipython-input-329-7aeec184221c> in <module>()\n     69                             od_wait=50,verbose=False)\n     70     \n     71     sl.add(learner) \n     72     sl.add_meta(meta_learner)\n     73     # Train the ensemble\n---> 74     sl.fit(X_train, y_train)\n     75     preds = sl.predict(X_train)\n     76     print(rmse(y_train, preds))\n     77     sls.append(sl)\n     78 #    results.append(mlens.metrics.rmse(y_train, ensemble.predict(X_train)),\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=SuperLearner(array_check=2, backend=None, folds=... scorer=None, shuffle=False,\n       verbose=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), **kwargs={})\n    511         X, y = check_inputs(X, y, self.array_check)\n    512 \n    513         if self.model_selection:\n    514             self._id_train.fit(X)\n    515 \n--> 516         out = self._backend.fit(X, y, **kwargs)\n        out = undefined\n        self._backend.fit = <bound method Sequential.fit of Sequential(backe...ormers=[])],\n   verbose=0)],\n      verbose=True)>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        kwargs = {}\n    517         if out is not self._backend:\n    518             # fit_transform\n    519             return out\n    520         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), **kwargs={})\n    153 \n    154         f, t0 = print_job(self, \"Fitting\")\n    155 \n    156         with ParallelProcessing(self.backend, self.n_jobs,\n    157                                 max(self.verbose - 4, 0)) as manager:\n--> 158             out = manager.stack(self, 'fit', X, y, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True)\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        kwargs = {}\n    159 \n    160         if self.verbose:\n    161             print_time(t0, \"{:<35}\".format(\"Fit complete\"), file=f)\n    162 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True), job='fit', X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), path=None, return_preds=False, wart_start=False, split=True, **kwargs={})\n    650             Prediction array(s).\n    651         \"\"\"\n    652         out = self.initialize(\n    653             job=job, X=X, y=y, path=path, warm_start=wart_start,\n    654             return_preds=return_preds, split=split, stack=True)\n--> 655         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True)\n        out = {}\n        kwargs = {}\n    656 \n    657     def process(self, caller, out, **kwargs):\n    658         \"\"\"Process job.\n    659 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True), out=None, **kwargs={})\n    695                       backend=self.backend) as parallel:\n    696 \n    697             for task in caller:\n    698                 self.job.clear()\n    699 \n--> 700                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    701 \n    702                 if task.name in return_names:\n    703                     out.append(self.get_preds(dtype=_dtype(task)))\n    704 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), parallel=Parallel(n_jobs=-1), **kwargs={})\n    716         task.setup(self.job.predict_in, self.job.y, self.job.job)\n    717 \n    718         if not task.__no_output__:\n    719             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    720 \n--> 721         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    722 \n    723         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    724             self._propagate_features(task)\n    725 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('adaboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ...], 'job': 'fit', 'main': {'P': array([[0.09273013, 0.06923506, 0.11517469, ...,... 0.10780568,\n        0.10646164]], dtype=float32), 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None)]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Fri Feb  9 16:00:37 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if not path:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('adaboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ...])\n    129         if not path:\n    130             path = self.path\n    131         t0 = time()\n    132         transformers = self._load_preprocess(path)\n    133 \n--> 134         self._fit(transformers)\n        self._fit = <bound method SubLearner._fit of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n    135 \n    136         if self.out_array is not None:\n    137             self._predict(transformers, self.scorer is not None)\n    138 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in _fit(self=<mlens.parallel.learner.SubLearner object>, transformers=None)\n    175         t0 = time()\n    176         if transformers:\n    177             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n    178 \n    179         # Fit estimator\n--> 180         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method BaseForest.fit of RandomForestRegr...one, verbose=False,\n           warm_start=False)>\n        xtemp = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        ytemp = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181         self.fit_time_ = time() - t0\n    182 \n    183     def _load_preprocess(self, path):\n    184         \"\"\"Load preprocessing pipeline\"\"\"\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...None, verbose=False,\n           warm_start=False), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,... 0.    ,  1.    ,  0.    ]],\n      dtype=float32), y=array([[0.06578774],\n       [0.22234323],\n      ...28  ],\n       [0.22840966],\n       [0.10750821]]), sample_weight=None)\n    311                 random_state.randint(MAX_INT, size=len(self.estimators_))\n    312 \n    313             trees = []\n    314             for i in range(n_more_estimators):\n    315                 tree = self._make_estimator(append=False,\n--> 316                                             random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    317                 trees.append(tree)\n    318 \n    319             # Parallel loop: we use the threading backend as the Cython code\n    320             # for fitting the trees is internally releasing the Python GIL\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py in _make_estimator(self=RandomForestRegressor(bootstrap=True, criterion=...None, verbose=False,\n           warm_start=False), append=False, random_state=<mtrand.RandomState object>)\n    120         \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n    121 \n    122         Warning: This method should be used to properly instantiate new\n    123         sub-estimators.\n    124         \"\"\"\n--> 125         estimator = clone(self.base_estimator_)\n        estimator = undefined\n        self.base_estimator_ = DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best')\n    126         estimator.set_params(**dict((p, getattr(self, p))\n    127                                     for p in self.estimator_params))\n    128 \n    129         if random_state is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in clone(estimator=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), safe=True)\n     55             raise TypeError(\"Cannot clone object '%s' (type %s): \"\n     56                             \"it does not seem to be a scikit-learn estimator \"\n     57                             \"as it does not implement a 'get_params' methods.\"\n     58                             % (repr(estimator), type(estimator)))\n     59     klass = estimator.__class__\n---> 60     new_object_params = estimator.get_params(deep=False)\n        new_object_params = undefined\n        estimator.get_params = <bound method BaseEstimator.get_params of Decisi...esort=False, random_state=None, splitter='best')>\n     61     for name, param in six.iteritems(new_object_params):\n     62         new_object_params[name] = clone(param, safe=False)\n     63     new_object = klass(**new_object_params)\n     64     params_set = new_object.get_params(deep=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Launch job\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, transformers)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Fit estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_time_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 316\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nIndexError                                         Fri Feb  9 16:00:37 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if not path:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('adaboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ...])\n    129         if not path:\n    130             path = self.path\n    131         t0 = time()\n    132         transformers = self._load_preprocess(path)\n    133 \n--> 134         self._fit(transformers)\n        self._fit = <bound method SubLearner._fit of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n    135 \n    136         if self.out_array is not None:\n    137             self._predict(transformers, self.scorer is not None)\n    138 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in _fit(self=<mlens.parallel.learner.SubLearner object>, transformers=None)\n    175         t0 = time()\n    176         if transformers:\n    177             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n    178 \n    179         # Fit estimator\n--> 180         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method BaseForest.fit of RandomForestRegr...one, verbose=False,\n           warm_start=False)>\n        xtemp = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        ytemp = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181         self.fit_time_ = time() - t0\n    182 \n    183     def _load_preprocess(self, path):\n    184         \"\"\"Load preprocessing pipeline\"\"\"\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...None, verbose=False,\n           warm_start=False), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,... 0.    ,  1.    ,  0.    ]],\n      dtype=float32), y=array([[0.06578774],\n       [0.22234323],\n      ...28  ],\n       [0.22840966],\n       [0.10750821]]), sample_weight=None)\n    311                 random_state.randint(MAX_INT, size=len(self.estimators_))\n    312 \n    313             trees = []\n    314             for i in range(n_more_estimators):\n    315                 tree = self._make_estimator(append=False,\n--> 316                                             random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    317                 trees.append(tree)\n    318 \n    319             # Parallel loop: we use the threading backend as the Cython code\n    320             # for fitting the trees is internally releasing the Python GIL\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py in _make_estimator(self=RandomForestRegressor(bootstrap=True, criterion=...None, verbose=False,\n           warm_start=False), append=False, random_state=<mtrand.RandomState object>)\n    120         \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n    121 \n    122         Warning: This method should be used to properly instantiate new\n    123         sub-estimators.\n    124         \"\"\"\n--> 125         estimator = clone(self.base_estimator_)\n        estimator = undefined\n        self.base_estimator_ = DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best')\n    126         estimator.set_params(**dict((p, getattr(self, p))\n    127                                     for p in self.estimator_params))\n    128 \n    129         if random_state is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in clone(estimator=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), safe=True)\n     55             raise TypeError(\"Cannot clone object '%s' (type %s): \"\n     56                             \"it does not seem to be a scikit-learn estimator \"\n     57                             \"as it does not implement a 'get_params' methods.\"\n     58                             % (repr(estimator), type(estimator)))\n     59     klass = estimator.__class__\n---> 60     new_object_params = estimator.get_params(deep=False)\n        new_object_params = undefined\n        estimator.get_params = <bound method BaseEstimator.get_params of Decisi...esort=False, random_state=None, splitter='best')>\n     61     for name, param in six.iteritems(new_object_params):\n     62         new_object_params[name] = clone(param, safe=False)\n     63     new_object = klass(**new_object_params)\n     64     params_set = new_object.get_params(deep=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-329-7aeec184221c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_learner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Train the ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m# fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         with ParallelProcessing(self.backend, self.n_jobs,\n\u001b[1;32m    157\u001b[0m                                 max(self.verbose - 4, 0)) as manager:\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(self, caller, job, X, y, path, return_preds, wart_start, split, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwart_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             return_preds=return_preds, split=split, stack=True)\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, caller, out, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, task, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_prediction_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__threading__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__no_output__\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_feature_prop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, args, parallel)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         parallel(delayed(sublearner, not _threading)()\n\u001b[0;32m--> 152\u001b[0;31m                  \u001b[0;32mfor\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                  for sublearner in learner(args, 'main'))\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m: JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 16, 0, 7, 95325), 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2CB284014A464058AFF9C38F92506A27']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 16, 0, 7, 95325), 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2CB284014A464058AFF9C38F92506A27'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 16, 0, 7, 95325), 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '47BCA161A21C47F1AAA4416D34B8AF5B', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from mlens.ensemble import SuperLearner\\nimport m...(X_test)))\\n\\n#    print_scores(scores_df, 'mlens')\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-329-7aeec184221c>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fefe41d5b38, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fefeecc5a50, file \"<ipython-input-329-7aeec184221c>\", line 50>\n        result = <ExecutionResult object at 7fefe41d5b38, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fefeecc5a50, file \"<ipython-input-329-7aeec184221c>\", line 50>, result=<ExecutionResult object at 7fefe41d5b38, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fefeecc5a50, file \"<ipython-input-329-7aeec184221c>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/scratch/baruselli/kaggle_nomad/<ipython-input-329-7aeec184221c> in <module>()\n     69                             od_wait=50,verbose=False)\n     70     \n     71     sl.add(learner) \n     72     sl.add_meta(meta_learner)\n     73     # Train the ensemble\n---> 74     sl.fit(X_train, y_train)\n     75     preds = sl.predict(X_train)\n     76     print(rmse(y_train, preds))\n     77     sls.append(sl)\n     78 #    results.append(mlens.metrics.rmse(y_train, ensemble.predict(X_train)),\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=SuperLearner(array_check=2, backend=None, folds=... scorer=None, shuffle=False,\n       verbose=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), **kwargs={})\n    511         X, y = check_inputs(X, y, self.array_check)\n    512 \n    513         if self.model_selection:\n    514             self._id_train.fit(X)\n    515 \n--> 516         out = self._backend.fit(X, y, **kwargs)\n        out = undefined\n        self._backend.fit = <bound method Sequential.fit of Sequential(backe...ormers=[])],\n   verbose=0)],\n      verbose=True)>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        kwargs = {}\n    517         if out is not self._backend:\n    518             # fit_transform\n    519             return out\n    520         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/ensemble/base.py in fit(self=Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), **kwargs={})\n    153 \n    154         f, t0 = print_job(self, \"Fitting\")\n    155 \n    156         with ParallelProcessing(self.backend, self.n_jobs,\n    157                                 max(self.verbose - 4, 0)) as manager:\n--> 158             out = manager.stack(self, 'fit', X, y, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True)\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        kwargs = {}\n    159 \n    160         if self.verbose:\n    161             print_time(t0, \"{:<35}\".format(\"Fit complete\"), file=f)\n    162 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True), job='fit', X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), path=None, return_preds=False, wart_start=False, split=True, **kwargs={})\n    650             Prediction array(s).\n    651         \"\"\"\n    652         out = self.initialize(\n    653             job=job, X=X, y=y, path=path, warm_start=wart_start,\n    654             return_preds=return_preds, split=split, stack=True)\n--> 655         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True)\n        out = {}\n        kwargs = {}\n    656 \n    657     def process(self, caller, out, **kwargs):\n    658         \"\"\"Process job.\n    659 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...formers=[])],\n   verbose=0)],\n      verbose=True), out=None, **kwargs={})\n    695                       backend=self.backend) as parallel:\n    696 \n    697             for task in caller:\n    698                 self.job.clear()\n    699 \n--> 700                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    701 \n    702                 if task.name in return_names:\n    703                     out.append(self.get_preds(dtype=_dtype(task)))\n    704 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), parallel=Parallel(n_jobs=-1), **kwargs={})\n    716         task.setup(self.job.predict_in, self.job.y, self.job.job)\n    717 \n    718         if not task.__no_output__:\n    719             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    720 \n--> 721         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    722 \n    723         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    724             self._propagate_features(task)\n    725 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('adaboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ...], 'job': 'fit', 'main': {'P': array([[0.09273013, 0.06923506, 0.11517469, ...,... 0.10780568,\n        0.10646164]], dtype=float32), 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False,\n    raise_on_exception=True, scorer=None)]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Fri Feb  9 16:00:37 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if not path:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('adaboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('adaboostregressor.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.3', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.4', <mlens.parallel.learner.IndexedEstimator object>), ('elasticnet.0.5', <mlens.parallel.learner.IndexedEstimator object>), ('catboostregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.0', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('gradientboostingregressor.0.3', <mlens.parallel.learner.IndexedEstimator object>), ...])\n    129         if not path:\n    130             path = self.path\n    131         t0 = time()\n    132         transformers = self._load_preprocess(path)\n    133 \n--> 134         self._fit(transformers)\n        self._fit = <bound method SubLearner._fit of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n    135 \n    136         if self.out_array is not None:\n    137             self._predict(transformers, self.scorer is not None)\n    138 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in _fit(self=<mlens.parallel.learner.SubLearner object>, transformers=None)\n    175         t0 = time()\n    176         if transformers:\n    177             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n    178 \n    179         # Fit estimator\n--> 180         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method BaseForest.fit of RandomForestRegr...one, verbose=False,\n           warm_start=False)>\n        xtemp = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        ytemp = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181         self.fit_time_ = time() - t0\n    182 \n    183     def _load_preprocess(self, path):\n    184         \"\"\"Load preprocessing pipeline\"\"\"\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...None, verbose=False,\n           warm_start=False), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,... 0.    ,  1.    ,  0.    ]],\n      dtype=float32), y=array([[0.06578774],\n       [0.22234323],\n      ...28  ],\n       [0.22840966],\n       [0.10750821]]), sample_weight=None)\n    311                 random_state.randint(MAX_INT, size=len(self.estimators_))\n    312 \n    313             trees = []\n    314             for i in range(n_more_estimators):\n    315                 tree = self._make_estimator(append=False,\n--> 316                                             random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    317                 trees.append(tree)\n    318 \n    319             # Parallel loop: we use the threading backend as the Cython code\n    320             # for fitting the trees is internally releasing the Python GIL\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py in _make_estimator(self=RandomForestRegressor(bootstrap=True, criterion=...None, verbose=False,\n           warm_start=False), append=False, random_state=<mtrand.RandomState object>)\n    120         \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n    121 \n    122         Warning: This method should be used to properly instantiate new\n    123         sub-estimators.\n    124         \"\"\"\n--> 125         estimator = clone(self.base_estimator_)\n        estimator = undefined\n        self.base_estimator_ = DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best')\n    126         estimator.set_params(**dict((p, getattr(self, p))\n    127                                     for p in self.estimator_params))\n    128 \n    129         if random_state is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in clone(estimator=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), safe=True)\n     55             raise TypeError(\"Cannot clone object '%s' (type %s): \"\n     56                             \"it does not seem to be a scikit-learn estimator \"\n     57                             \"as it does not implement a 'get_params' methods.\"\n     58                             % (repr(estimator), type(estimator)))\n     59     klass = estimator.__class__\n---> 60     new_object_params = estimator.get_params(deep=False)\n        new_object_params = undefined\n        estimator.get_params = <bound method BaseEstimator.get_params of Decisi...esort=False, random_state=None, splitter='best')>\n     61     for name, param in six.iteritems(new_object_params):\n     62         new_object_params[name] = clone(param, safe=False)\n     63     new_object = klass(**new_object_params)\n     64     params_set = new_object.get_params(deep=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "import mlens\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.metrics import rmse\n",
    "\n",
    "from mlens.metrics import make_scorer\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "learners1=[g[0].best_estimator_ for g in results.values()]\n",
    "learners2=[g[1].best_estimator_ for g in results.values()]\n",
    "learners=[learners1,learners2]\n",
    "\n",
    "# Instantiate the ensemble with 10 folds\n",
    "#meta_learner1=CatBoostRegressor(iterations=1200,\n",
    "#                            learning_rate=0.03,\n",
    "#                            depth=4,\n",
    "#                            loss_function='RMSE',\n",
    "#                            eval_metric='RMSE',\n",
    "##                            random_seed=SEED,\n",
    "#                            od_type='Iter',\n",
    "#                            od_wait=50,verbose=False)\n",
    "\n",
    "#import copy\n",
    "#meta_learner2=copy.deepcopy(meta_learner1)\n",
    "\n",
    "#sl1 = SuperLearner(\n",
    "#    folds=5,\n",
    "#    verbose=True,\n",
    "##    scorer=mlens.metrics.rmse\n",
    "#)\n",
    "#sl2 = SuperLearner(\n",
    "#    folds=5,\n",
    "#    verbose=True,\n",
    "#    scorer=mlens.metrics.rmse\n",
    "#)\n",
    "\n",
    "# Add the base learners and the meta learner\n",
    "#sl1.add(learners1) \n",
    "#sl1.add_meta(meta_learner1)\n",
    "#sl2.add(learners2) \n",
    "#sl2.add_meta(meta_learner2)\n",
    "\n",
    "#sls=[sl1,sl2]\n",
    "#evaluator\n",
    "#evl = Evaluator(make_scorer(mlens.metrics.rmse), cv=5, shuffle=False)\n",
    "sls=[]\n",
    "for learner,y in zip(learners,y_col):\n",
    "    print(y)\n",
    "    y_train=df_total_train_eval[y].values\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    \n",
    "    #evl.fit(X_train, y_train, sl, {}, n_iter=1)\n",
    "    from mlens.ensemble import SuperLearner\n",
    "    \n",
    "    sl = SuperLearner(\n",
    "    folds=5,\n",
    "    verbose=True,\n",
    "    #    scorer=mlens.metrics.rmse\n",
    "    )\n",
    "    \n",
    "    meta_learner=CatBoostRegressor(iterations=1200,\n",
    "                            learning_rate=0.03,\n",
    "                            depth=4,\n",
    "                            loss_function='RMSE',\n",
    "                            eval_metric='RMSE',\n",
    "#                            random_seed=SEED,\n",
    "                            od_type='Iter',\n",
    "                            od_wait=50,verbose=False)\n",
    "    \n",
    "    sl.add(learner) \n",
    "    sl.add_meta(meta_learner)\n",
    "    # Train the ensemble\n",
    "    sl.fit(X_train, y_train)\n",
    "    preds = sl.predict(X_train)\n",
    "    print(rmse(y_train, preds))\n",
    "    sls.append(sl)\n",
    "#    results.append(mlens.metrics.rmse(y_train, ensemble.predict(X_train)),\n",
    "#                          evl.summary['test_score_mean']['superlearner'],\n",
    "#                          evl.summary['test_score_std']['superlearner'],\n",
    "#                          mlens.metrics.rmse(y_test, ensemble.predict(X_test)))\n",
    "\n",
    "#    print_scores(scores_df, 'mlens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from mlens.ensemble import SuperLearner\n",
    "import mlens\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.metrics import rmse\n",
    "\n",
    "\n",
    "\n",
    "learners1=[grid[0].best_estimator_ for grid in results.values()]\n",
    "learners2=[grid[1].best_estimator_ for grid in results.values()]\n",
    "\n",
    "grid_sl=[]\n",
    "\n",
    "tries=3\n",
    "#grid search for the meta learner         \n",
    "for depth, iterations, learning_rate in zip (scipy.stats.randint(1,5).rvs(tries),\n",
    "                                              scipy.stats.randint(1000,2000).rvs(tries),    \n",
    "                                              lognuniform(low=-2,high=-1,base=10,size=tries)):\n",
    "    print(depth, iterations, learning_rate)\n",
    "    \n",
    "\n",
    "    # Instantiate the ensemble with 10 folds\n",
    "    meta_learner1=CatBoostRegressor(iterations=iterations,\n",
    "                                learning_rate=learning_rate,\n",
    "                                depth=depth,\n",
    "                                loss_function='RMSE',\n",
    "                                eval_metric='RMSE',\n",
    "    #                            random_seed=SEED,\n",
    "                                od_type='Iter',\n",
    "                                od_wait=50,verbose=False)\n",
    "\n",
    "    import copy\n",
    "    meta_learner2=copy.deepcopy(meta_learner1)\n",
    "\n",
    "    sl1 = SuperLearner(\n",
    "        folds=5,\n",
    "        verbose=True,\n",
    "        scorer=mlens.metrics.rmse\n",
    "    )\n",
    "    sl2 = SuperLearner(\n",
    "        folds=5,\n",
    "        verbose=True,\n",
    "        scorer=mlens.metrics.rmse\n",
    "    )\n",
    "\n",
    "    # Add the base learners and the meta learner\n",
    "    sl1.add(learners1) \n",
    "    sl1.add_meta(meta_learner1)\n",
    "    sl2.add(learners2) \n",
    "    sl2.add_meta(meta_learner2)\n",
    "\n",
    "\n",
    "\n",
    "    sls=[sl1,sl2]\n",
    "    #evaluator\n",
    "    #evl = Evaluator(make_scorer(mlens.metrics.rmse), cv=5, shuffle=False)\n",
    "\n",
    "    for i,y in enumerate(y_col):\n",
    "        print(y)\n",
    "        y_train=df_total_train_eval[y].values\n",
    "        #print(X_train.shape,y_train.shape)\n",
    "\n",
    "        #evl.fit(X_train, y_train, sl, {}, n_iter=1)\n",
    "\n",
    "        # Train the ensemble\n",
    "        sls[i].fit(X_train, y_train)\n",
    "        preds = sls[i].predict(X_train)\n",
    "        print(rmse(y_train, preds))\n",
    "        \n",
    "        grid_sl.append(depth, iterations, learning_rate,sls)\n",
    "        \n",
    "        \n",
    "    #    results.append(mlens.metrics.rmse(y_train, ensemble.predict(X_train)),\n",
    "    #                          evl.summary['test_score_mean']['superlearner'],\n",
    "    #                          evl.summary['test_score_std']['superlearner'],\n",
    "    #                          mlens.metrics.rmse(y_test, ensemble.predict(X_test)))\n",
    "\n",
    "    #    print_scores(scores_df, 'mlens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job\n",
      "Preprocessing 1 preprocessing pipelines over 2 CV folds\n"
     ]
    },
    {
     "ename": "JoblibIndexError",
     "evalue": "JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 58, 38, 876118), 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2CB284014A464058AFF9C38F92506A27']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 58, 38, 876118), 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2CB284014A464058AFF9C38F92506A27'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 58, 38, 876118), 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-272-5891709ed14f>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fefec7520b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fefe4066ed0, file \"<ipython-input-272-5891709ed14f>\", line 12>\n        result = <ExecutionResult object at 7fefec7520b8, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fefe4066ed0, file \"<ipython-input-272-5891709ed14f>\", line 12>, result=<ExecutionResult object at 7fefec7520b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fefe4066ed0, file \"<ipython-input-272-5891709ed14f>\", line 12>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/scratch/baruselli/kaggle_nomad/<ipython-input-272-5891709ed14f> in <module>()\n     12 evl.fit(\n     13     X_train, y_train,\n     14     meta_learners,\n     15     param_dicts,\n     16     preprocessing={'meta': preprocess},\n---> 17     n_iter=5                           # bump this up to do a larger grid search\n     18 )\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), estimators=[('gb', XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1)), ('el', ElasticNet(alpha=1e-06, copy_X=True, fit_interce...selection='cyclic', tol=0.0001, warm_start=False))], param_dicts={'el': {'alpha': <scipy.stats._distn_infrastructure.rv_frozen object>, 'l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'gb': {'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>, 'reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen object>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object>}}, n_iter=5, preprocessing={'meta': [SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False)]})\n    502             class instance with stored estimator evaluation results in\n    503             the ``results`` attribute.\n    504         \"\"\"\n    505         job = set_job(estimators, preprocessing)\n    506         self._initialize(job, estimators, preprocessing, param_dicts, n_iter)\n--> 507         self._fit(X, y, job)\n        self._fit = <bound method BaseEval._fit of <mlens.model_selection.model_selection.Evaluator object>>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        job = 'preprocess-evaluate'\n    508         self._get_results()\n    509         return self\n    510 \n    511     def _initialize(self, job, estimators, preprocessing, param_dicts, n_iter):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), job='preprocess-evaluate')\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n    179         with ParallelEvaluation(self.backend, self.n_jobs, verbose) as manager:\n--> 180             manager.process(self, job, X, y)\n        manager.process = <bound method ParallelEvaluation.process of <mlens.parallel.backend.ParallelEvaluation object>>\n        self = <mlens.model_selection.model_selection.Evaluator object>\n        job = 'preprocess-evaluate'\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181 \n    182     def collect(self, path, case):\n    183         \"\"\"Collect cache estimators\"\"\"\n    184         if case == 'transformers':\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelEvaluation object>, caller=<mlens.model_selection.model_selection.Evaluator object>, case='preprocess-evaluate', X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), path=None, **kwargs={})\n    832         with Parallel(n_jobs=self.n_jobs, temp_folder=tf, max_nbytes=None,\n    833                       mmap_mode='w+', verbose=self.verbose,\n    834                       backend=self.backend) as parallel:\n    835 \n    836             caller.indexer.fit(self.job.predict_in, self.job.y, self.job.job)\n--> 837             caller(parallel, self.job.args(**kwargs), case)\n        caller = <mlens.model_selection.model_selection.Evaluator object>\n        parallel = Parallel(n_jobs=-1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        case = 'preprocess-evaluate'\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in __call__(self=<mlens.model_selection.model_selection.Evaluator object>, parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}, case='preprocess-evaluate')\n    135             # Second test is for already fitted pipes - need to be cached\n    136             if self.verbose >= 2:\n    137                 safe_print(self._print_prep_start(), file=f)\n    138                 t1 = time()\n    139 \n--> 140             self._run('transformers', parallel, args)\n        self._run = <bound method BaseEval._run of <mlens.model_selection.model_selection.Evaluator object>>\n        parallel = Parallel(n_jobs=-1)\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    141             if 'preprocess' in case:\n    142                 self.collect(args['dir'], 'transformers')\n    143 \n    144             if self.verbose >= 2:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _run(self=<mlens.model_selection.model_selection.Evaluator object>, case='transformers', parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}})\n    169         else:\n    170             generator = self._learners\n    171             inp = 'main'\n    172 \n    173         parallel(delayed(subtask, not _threading)()\n--> 174                  for task in generator for subtask in task(args, inp))\n        generator = [EvalTransformer(backend='threading', dtype=<clas... n_jobs=-1, name='meta', raise_on_exception=True)]\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEval._run.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Fri Feb  9 14:58:39 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubTransformer object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubTransformer object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubTransformer object>)\n    246         if not parent.__no_output__:\n    247             self.output_columns = parent.output_columns[index[0]]\n    248 \n    249     def __call__(self):\n    250         \"\"\"Launch job\"\"\"\n--> 251         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubTransformer object>\n        self.job = 'fit'\n    252 \n    253     def predict(self):\n    254         \"\"\"Dump transformers for prediction\"\"\"\n    255         self._transform()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubTransformer object>, path=[])\n    281         t0 = time()\n    282         xtemp, ytemp = slice_array(\n    283             self.in_array, self.targets, self.in_index)\n    284 \n    285         t0_f = time()\n--> 286         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method Pipeline.fit of Pipeline(name='pip...se,\n       verbose=False))],\n     return_y=True)>\n        xtemp = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]])\n        ytemp = array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073])\n    287         self.transform_time_ = time() - t0_f\n    288 \n    289         if self.out_array is not None:\n    290             self._transform()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in fit(self=Pipeline(name='pipeline-27',\n     pipeline=[('su...lse,\n       verbose=False))],\n     return_y=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073]))\n    104         Returns\n    105         -------\n    106         self : instance\n    107             Fitted pipeline\n    108         \"\"\"\n--> 109         return self._run(True, False, X, y)\n        self._run = <bound method Pipeline._run of Pipeline(name='pi...se,\n       verbose=False))],\n     return_y=True)>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073])\n    110 \n    111     def transform(self, X, y=None):\n    112         \"\"\"Transform pipeline.\n    113 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in _run(self=Pipeline(name='pipeline-27',\n     pipeline=[('su...lse,\n       verbose=False))],\n     return_y=True), fit=True, process=False, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073]))\n     57         if out is not False:\n     58             return out\n     59 \n     60         if fit:\n     61             self._pipeline = [(tr_name, clone(tr))\n---> 62                               for tr_name, tr in self.pipeline]\n        tr_name = undefined\n        tr = undefined\n        self.pipeline = [('superlearner', SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False))]\n     63 \n     64         for tr_name, tr in self._pipeline:\n     65             if fit:\n     66                 tr.fit(X, y)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in <listcomp>(.0=<list_iterator object>)\n     57         if out is not False:\n     58             return out\n     59 \n     60         if fit:\n     61             self._pipeline = [(tr_name, clone(tr))\n---> 62                               for tr_name, tr in self.pipeline]\n        tr_name = 'superlearner'\n        tr = SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False)\n     63 \n     64         for tr_name, tr in self._pipeline:\n     65             if fit:\n     66                 tr.fit(X, y)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False), safe=True)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'array_check': 2, 'backend': None, 'folds': 2, 'layers': [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)], 'model_selection': True, 'n_jobs': None, 'raise_on_exception': True, 'random_state': None, 'sample_size': 20, 'scorer': None, ...}\n        name = 'layers'\n        param = [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)]\n        safe = True\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'n_jobs': -1, 'name': 'layer-1', 'propagate_features': None, 'raise_on_exception': True, 'random_state': None, 'shuffle': False, 'stack': [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])], 'verbose': 0}\n        name = 'stack'\n        param = [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])]\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[]), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'indexer': FoldIndex(X=None, folds=2, raise_on_exception=True), 'learners': [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)], 'n_jobs': -1, 'name': 'group-32', 'raise_on_exception': True, 'transformers': []}\n        name = 'learners'\n        param = [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)]\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'attr': 'predict', 'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'estimator': XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), 'indexer': FoldIndex(X=None, folds=2, raise_on_exception=True), 'n_jobs': -1, 'name': 'xgb', 'preprocess': None, 'proba': False, 'raise_on_exception': True, ...}\n        name = 'estimator'\n        param = XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1)\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), safe=False)\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n     63         new_object_params[name] = clone(param, safe=False)\n     64     new_object = klass(**new_object_params)\n---> 65     params_set = new_object.get_params(deep=False)\n        params_set = undefined\n        new_object.get_params = <bound method XGBModel.get_params of XGBRegresso..._pos_weight=1, seed=0, silent=True, subsample=1)>\n     66 \n     67     # quick sanity check of the parameters of the clone\n     68     for name in new_object_params:\n     69         param1 = new_object_params[name]\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/xgboost/sklearn.py in get_params(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), deep=False)\n    163             raise XGBoostError('need to call fit beforehand')\n    164         return self._Booster\n    165 \n    166     def get_params(self, deep=False):\n    167         \"\"\"Get parameter.s\"\"\"\n--> 168         params = super(XGBModel, self).get_params(deep=deep)\n        params = undefined\n        self.get_params = <bound method XGBModel.get_params of XGBRegresso..._pos_weight=1, seed=0, silent=True, subsample=1)>\n        deep = False\n    169         if params['missing'] is np.nan:\n    170             params['missing'] = None  # sklearn doesn't handle nan. see #4725\n    171         if not params.get('eval_metric', True):\n    172             del params['eval_metric']  # don't give as None param to Booster\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;34m\"\"\"Launch job\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mt0_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_time_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, fit, process, X, y)\u001b[0m\n\u001b[1;32m     61\u001b[0m             self._pipeline = [(tr_name, clone(tr))\n\u001b[0;32m---> 62\u001b[0;31m                               for tr_name, tr in self.pipeline]\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m             self._pipeline = [(tr_name, clone(tr))\n\u001b[0;32m---> 62\u001b[0;31m                               for tr_name, tr in self.pipeline]\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;34m\"\"\"Get parameter.s\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'missing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nIndexError                                         Fri Feb  9 14:58:39 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubTransformer object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubTransformer object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubTransformer object>)\n    246         if not parent.__no_output__:\n    247             self.output_columns = parent.output_columns[index[0]]\n    248 \n    249     def __call__(self):\n    250         \"\"\"Launch job\"\"\"\n--> 251         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubTransformer object>\n        self.job = 'fit'\n    252 \n    253     def predict(self):\n    254         \"\"\"Dump transformers for prediction\"\"\"\n    255         self._transform()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubTransformer object>, path=[])\n    281         t0 = time()\n    282         xtemp, ytemp = slice_array(\n    283             self.in_array, self.targets, self.in_index)\n    284 \n    285         t0_f = time()\n--> 286         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method Pipeline.fit of Pipeline(name='pip...se,\n       verbose=False))],\n     return_y=True)>\n        xtemp = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]])\n        ytemp = array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073])\n    287         self.transform_time_ = time() - t0_f\n    288 \n    289         if self.out_array is not None:\n    290             self._transform()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in fit(self=Pipeline(name='pipeline-27',\n     pipeline=[('su...lse,\n       verbose=False))],\n     return_y=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073]))\n    104         Returns\n    105         -------\n    106         self : instance\n    107             Fitted pipeline\n    108         \"\"\"\n--> 109         return self._run(True, False, X, y)\n        self._run = <bound method Pipeline._run of Pipeline(name='pi...se,\n       verbose=False))],\n     return_y=True)>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073])\n    110 \n    111     def transform(self, X, y=None):\n    112         \"\"\"Transform pipeline.\n    113 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in _run(self=Pipeline(name='pipeline-27',\n     pipeline=[('su...lse,\n       verbose=False))],\n     return_y=True), fit=True, process=False, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073]))\n     57         if out is not False:\n     58             return out\n     59 \n     60         if fit:\n     61             self._pipeline = [(tr_name, clone(tr))\n---> 62                               for tr_name, tr in self.pipeline]\n        tr_name = undefined\n        tr = undefined\n        self.pipeline = [('superlearner', SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False))]\n     63 \n     64         for tr_name, tr in self._pipeline:\n     65             if fit:\n     66                 tr.fit(X, y)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in <listcomp>(.0=<list_iterator object>)\n     57         if out is not False:\n     58             return out\n     59 \n     60         if fit:\n     61             self._pipeline = [(tr_name, clone(tr))\n---> 62                               for tr_name, tr in self.pipeline]\n        tr_name = 'superlearner'\n        tr = SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False)\n     63 \n     64         for tr_name, tr in self._pipeline:\n     65             if fit:\n     66                 tr.fit(X, y)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False), safe=True)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'array_check': 2, 'backend': None, 'folds': 2, 'layers': [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)], 'model_selection': True, 'n_jobs': None, 'raise_on_exception': True, 'random_state': None, 'sample_size': 20, 'scorer': None, ...}\n        name = 'layers'\n        param = [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)]\n        safe = True\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'n_jobs': -1, 'name': 'layer-1', 'propagate_features': None, 'raise_on_exception': True, 'random_state': None, 'shuffle': False, 'stack': [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])], 'verbose': 0}\n        name = 'stack'\n        param = [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])]\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[]), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'indexer': FoldIndex(X=None, folds=2, raise_on_exception=True), 'learners': [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)], 'n_jobs': -1, 'name': 'group-32', 'raise_on_exception': True, 'transformers': []}\n        name = 'learners'\n        param = [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)]\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'attr': 'predict', 'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'estimator': XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), 'indexer': FoldIndex(X=None, folds=2, raise_on_exception=True), 'n_jobs': -1, 'name': 'xgb', 'preprocess': None, 'proba': False, 'raise_on_exception': True, ...}\n        name = 'estimator'\n        param = XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1)\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), safe=False)\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n     63         new_object_params[name] = clone(param, safe=False)\n     64     new_object = klass(**new_object_params)\n---> 65     params_set = new_object.get_params(deep=False)\n        params_set = undefined\n        new_object.get_params = <bound method XGBModel.get_params of XGBRegresso..._pos_weight=1, seed=0, silent=True, subsample=1)>\n     66 \n     67     # quick sanity check of the parameters of the clone\n     68     for name in new_object_params:\n     69         param1 = new_object_params[name]\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/xgboost/sklearn.py in get_params(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), deep=False)\n    163             raise XGBoostError('need to call fit beforehand')\n    164         return self._Booster\n    165 \n    166     def get_params(self, deep=False):\n    167         \"\"\"Get parameter.s\"\"\"\n--> 168         params = super(XGBModel, self).get_params(deep=deep)\n        params = undefined\n        self.get_params = <bound method XGBModel.get_params of XGBRegresso..._pos_weight=1, seed=0, silent=True, subsample=1)>\n        deep = False\n    169         if params['missing'] is np.nan:\n    170             params['missing'] = None  # sklearn doesn't handle nan. see #4725\n    171         if not params.get('eval_metric', True):\n    172             del params['eval_metric']  # don't give as None param to Booster\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-5891709ed14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mparam_dicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m                           \u001b[0;31m# bump this up to do a larger grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, estimators, param_dicts, n_iter, preprocessing)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, job)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mParallelEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, caller, case, X, y, path, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mcaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parallel, args, case)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transformers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'preprocess'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, case, parallel, args)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         parallel(delayed(subtask, not _threading)()\n\u001b[0;32m--> 174\u001b[0;31m                  for task in generator for subtask in task(args, inp))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m: JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 58, 38, 876118), 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2CB284014A464058AFF9C38F92506A27']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 58, 38, 876118), 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2CB284014A464058AFF9C38F92506A27'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 58, 38, 876118), 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '62DC522F028F46B19CCAE3FB423F56E7', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='in_layer = SuperLearner(model_selection=True)\\nin...     # bump this up to do a larger grid search\\n)\\n', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-272-5891709ed14f>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fefec7520b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fefe4066ed0, file \"<ipython-input-272-5891709ed14f>\", line 12>\n        result = <ExecutionResult object at 7fefec7520b8, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fefe4066ed0, file \"<ipython-input-272-5891709ed14f>\", line 12>, result=<ExecutionResult object at 7fefec7520b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fefe4066ed0, file \"<ipython-input-272-5891709ed14f>\", line 12>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/scratch/baruselli/kaggle_nomad/<ipython-input-272-5891709ed14f> in <module>()\n     12 evl.fit(\n     13     X_train, y_train,\n     14     meta_learners,\n     15     param_dicts,\n     16     preprocessing={'meta': preprocess},\n---> 17     n_iter=5                           # bump this up to do a larger grid search\n     18 )\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), estimators=[('gb', XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1)), ('el', ElasticNet(alpha=1e-06, copy_X=True, fit_interce...selection='cyclic', tol=0.0001, warm_start=False))], param_dicts={'el': {'alpha': <scipy.stats._distn_infrastructure.rv_frozen object>, 'l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'gb': {'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>, 'reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen object>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object>}}, n_iter=5, preprocessing={'meta': [SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False)]})\n    502             class instance with stored estimator evaluation results in\n    503             the ``results`` attribute.\n    504         \"\"\"\n    505         job = set_job(estimators, preprocessing)\n    506         self._initialize(job, estimators, preprocessing, param_dicts, n_iter)\n--> 507         self._fit(X, y, job)\n        self._fit = <bound method BaseEval._fit of <mlens.model_selection.model_selection.Evaluator object>>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        job = 'preprocess-evaluate'\n    508         self._get_results()\n    509         return self\n    510 \n    511     def _initialize(self, job, estimators, preprocessing, param_dicts, n_iter):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), job='preprocess-evaluate')\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n    179         with ParallelEvaluation(self.backend, self.n_jobs, verbose) as manager:\n--> 180             manager.process(self, job, X, y)\n        manager.process = <bound method ParallelEvaluation.process of <mlens.parallel.backend.ParallelEvaluation object>>\n        self = <mlens.model_selection.model_selection.Evaluator object>\n        job = 'preprocess-evaluate'\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181 \n    182     def collect(self, path, case):\n    183         \"\"\"Collect cache estimators\"\"\"\n    184         if case == 'transformers':\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelEvaluation object>, caller=<mlens.model_selection.model_selection.Evaluator object>, case='preprocess-evaluate', X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), path=None, **kwargs={})\n    832         with Parallel(n_jobs=self.n_jobs, temp_folder=tf, max_nbytes=None,\n    833                       mmap_mode='w+', verbose=self.verbose,\n    834                       backend=self.backend) as parallel:\n    835 \n    836             caller.indexer.fit(self.job.predict_in, self.job.y, self.job.job)\n--> 837             caller(parallel, self.job.args(**kwargs), case)\n        caller = <mlens.model_selection.model_selection.Evaluator object>\n        parallel = Parallel(n_jobs=-1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        case = 'preprocess-evaluate'\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in __call__(self=<mlens.model_selection.model_selection.Evaluator object>, parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}, case='preprocess-evaluate')\n    135             # Second test is for already fitted pipes - need to be cached\n    136             if self.verbose >= 2:\n    137                 safe_print(self._print_prep_start(), file=f)\n    138                 t1 = time()\n    139 \n--> 140             self._run('transformers', parallel, args)\n        self._run = <bound method BaseEval._run of <mlens.model_selection.model_selection.Evaluator object>>\n        parallel = Parallel(n_jobs=-1)\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    141             if 'preprocess' in case:\n    142                 self.collect(args['dir'], 'transformers')\n    143 \n    144             if self.verbose >= 2:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _run(self=<mlens.model_selection.model_selection.Evaluator object>, case='transformers', parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}})\n    169         else:\n    170             generator = self._learners\n    171             inp = 'main'\n    172 \n    173         parallel(delayed(subtask, not _threading)()\n--> 174                  for task in generator for subtask in task(args, inp))\n        generator = [EvalTransformer(backend='threading', dtype=<clas... n_jobs=-1, name='meta', raise_on_exception=True)]\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('meta.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEval._run.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Fri Feb  9 14:58:39 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubTransformer object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubTransformer object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubTransformer object>)\n    246         if not parent.__no_output__:\n    247             self.output_columns = parent.output_columns[index[0]]\n    248 \n    249     def __call__(self):\n    250         \"\"\"Launch job\"\"\"\n--> 251         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubTransformer object>\n        self.job = 'fit'\n    252 \n    253     def predict(self):\n    254         \"\"\"Dump transformers for prediction\"\"\"\n    255         self._transform()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubTransformer object>, path=[])\n    281         t0 = time()\n    282         xtemp, ytemp = slice_array(\n    283             self.in_array, self.targets, self.in_index)\n    284 \n    285         t0_f = time()\n--> 286         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method Pipeline.fit of Pipeline(name='pip...se,\n       verbose=False))],\n     return_y=True)>\n        xtemp = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]])\n        ytemp = array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073])\n    287         self.transform_time_ = time() - t0_f\n    288 \n    289         if self.out_array is not None:\n    290             self._transform()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in fit(self=Pipeline(name='pipeline-27',\n     pipeline=[('su...lse,\n       verbose=False))],\n     return_y=True), X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073]))\n    104         Returns\n    105         -------\n    106         self : instance\n    107             Fitted pipeline\n    108         \"\"\"\n--> 109         return self._run(True, False, X, y)\n        self._run = <bound method Pipeline._run of Pipeline(name='pi...se,\n       verbose=False))],\n     return_y=True)>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073])\n    110 \n    111     def transform(self, X, y=None):\n    112         \"\"\"Transform pipeline.\n    113 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in _run(self=Pipeline(name='pipeline-27',\n     pipeline=[('su...lse,\n       verbose=False))],\n     return_y=True), fit=True, process=False, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....3757, 90.0011, ...,  0.    ,  0.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.23055601, 0.03449804,\n       0.21503073]))\n     57         if out is not False:\n     58             return out\n     59 \n     60         if fit:\n     61             self._pipeline = [(tr_name, clone(tr))\n---> 62                               for tr_name, tr in self.pipeline]\n        tr_name = undefined\n        tr = undefined\n        self.pipeline = [('superlearner', SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False))]\n     63 \n     64         for tr_name, tr in self._pipeline:\n     65             if fit:\n     66                 tr.fit(X, y)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/handles.py in <listcomp>(.0=<list_iterator object>)\n     57         if out is not False:\n     58             return out\n     59 \n     60         if fit:\n     61             self._pipeline = [(tr_name, clone(tr))\n---> 62                               for tr_name, tr in self.pipeline]\n        tr_name = 'superlearner'\n        tr = SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False)\n     63 \n     64         for tr_name, tr in self._pipeline:\n     65             if fit:\n     66                 tr.fit(X, y)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=SuperLearner(array_check=2, backend=None, folds=...scorer=None, shuffle=False,\n       verbose=False), safe=True)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'array_check': 2, 'backend': None, 'folds': 2, 'layers': [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)], 'model_selection': True, 'n_jobs': None, 'raise_on_exception': True, 'random_state': None, 'sample_size': 20, 'scorer': None, ...}\n        name = 'layers'\n        param = [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)]\n        safe = True\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'n_jobs': -1, 'name': 'layer-1', 'propagate_features': None, 'raise_on_exception': True, 'random_state': None, 'shuffle': False, 'stack': [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])], 'verbose': 0}\n        name = 'stack'\n        param = [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])]\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[])\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Group(backend='threading', dtype=<class 'numpy.f...up-32', raise_on_exception=True, transformers=[]), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'indexer': FoldIndex(X=None, folds=2, raise_on_exception=True), 'learners': [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)], 'n_jobs': -1, 'name': 'group-32', 'raise_on_exception': True, 'transformers': []}\n        name = 'learners'\n        param = [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)]\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=[Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)], safe=False)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        estimator_type = <class 'list'>\n        safe = False\n        estimator = [Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)]\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in <listcomp>(.0=<list_iterator object>)\n     46         that are not estimators.\n     47     \"\"\"\n     48     estimator_type = type(estimator)\n     49     # XXX: not handling dictionaries\n     50     if estimator_type in (list, tuple, set, frozenset):\n---> 51         return estimator_type([clone(e, safe=safe) for e in estimator])\n        e = Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None)\n     52     elif not hasattr(estimator, 'get_params'):\n     53         if not safe:\n     54             return copy.deepcopy(estimator)\n     55         else:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=Learner(attr='predict', backend='threading', dty...=False, raise_on_exception=True,\n    scorer=None), safe=False)\n     58                             \"as it does not implement a 'get_params' methods.\"\n     59                             % (repr(estimator), type(estimator)))\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n---> 63         new_object_params[name] = clone(param, safe=False)\n        new_object_params = {'attr': 'predict', 'backend': 'threading', 'dtype': <class 'numpy.float32'>, 'estimator': XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), 'indexer': FoldIndex(X=None, folds=2, raise_on_exception=True), 'n_jobs': -1, 'name': 'xgb', 'preprocess': None, 'proba': False, 'raise_on_exception': True, ...}\n        name = 'estimator'\n        param = XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1)\n        safe = False\n     64     new_object = klass(**new_object_params)\n     65     params_set = new_object.get_params(deep=False)\n     66 \n     67     # quick sanity check of the parameters of the clone\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/sklearn/base.py in clone(estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), safe=False)\n     60     klass = estimator.__class__\n     61     new_object_params = estimator.get_params(deep=False)\n     62     for name, param in six.iteritems(new_object_params):\n     63         new_object_params[name] = clone(param, safe=False)\n     64     new_object = klass(**new_object_params)\n---> 65     params_set = new_object.get_params(deep=False)\n        params_set = undefined\n        new_object.get_params = <bound method XGBModel.get_params of XGBRegresso..._pos_weight=1, seed=0, silent=True, subsample=1)>\n     66 \n     67     # quick sanity check of the parameters of the clone\n     68     for name in new_object_params:\n     69         param1 = new_object_params[name]\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/xgboost/sklearn.py in get_params(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), deep=False)\n    163             raise XGBoostError('need to call fit beforehand')\n    164         return self._Booster\n    165 \n    166     def get_params(self, deep=False):\n    167         \"\"\"Get parameter.s\"\"\"\n--> 168         params = super(XGBModel, self).get_params(deep=deep)\n        params = undefined\n        self.get_params = <bound method XGBModel.get_params of XGBRegresso..._pos_weight=1, seed=0, silent=True, subsample=1)>\n        deep = False\n    169         if params['missing'] is np.nan:\n    170             params['missing'] = None  # sklearn doesn't handle nan. see #4725\n    171         if not params.get('eval_metric', True):\n    172             del params['eval_metric']  # don't give as None param to Booster\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "in_layer = SuperLearner(model_selection=True)\n",
    "in_layer.add(base_learners)\n",
    "\n",
    "preprocess = [in_layer]\n",
    "\n",
    "evl = Evaluator(\n",
    "    scorer,\n",
    "    cv=2,\n",
    "    verbose=5,\n",
    ")\n",
    "\n",
    "evl.fit(\n",
    "    X_train, y_train,\n",
    "    meta_learners,\n",
    "    param_dicts,\n",
    "    preprocessing={'meta': preprocess},\n",
    "    n_iter=5                           # bump this up to do a larger grid search\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "E SuperLearner(array_check=2, backend=None, folds=5,\n",
      "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
      "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
      "   random_state=None, shuffle=False,\n",
      "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
      "   indexer=FoldIndex(X=None, folds=5, raise_on_ex...d37840>)],\n",
      "   n_jobs=-1, name='group-21', raise_on_exception=True, transformers=[])],\n",
      "   verbose=0)],\n",
      "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
      "       random_state=None, sample_size=20,\n",
      "       scorer=<function rmse at 0x7fefeed37840>, shuffle=False,\n",
      "       verbose=True)\n",
      "shapes: (2400, 21) (2400,)\n",
      "\n",
      "Predicting 2 layers\n",
      "Predict complete                    | 00:00:00\n",
      "Eg SuperLearner(array_check=2, backend=None, folds=5,\n",
      "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
      "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
      "   random_state=None, shuffle=False,\n",
      "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
      "   indexer=FoldIndex(X=None, folds=5, raise_on_ex...d37840>)],\n",
      "   n_jobs=-1, name='group-23', raise_on_exception=True, transformers=[])],\n",
      "   verbose=0)],\n",
      "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
      "       random_state=None, sample_size=20,\n",
      "       scorer=<function rmse at 0x7fefeed37840>, shuffle=False,\n",
      "       verbose=True)\n",
      "shapes: (2400, 21) (2400,)\n",
      "\n",
      "Predicting 2 layers\n",
      "Predict complete                    | 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#write to csv\n",
    "%load_ext autoreload\n",
    "%aimport varie\n",
    "%autoreload 2\n",
    "#I use a different model for E and Eg\n",
    "varie.make_csv2(df_total_train_eval,pd.DataFrame(),df_total_test,\n",
    "#         (ensemble.RandomForestRegressor(max_depth= 11, max_features='log2', n_estimators= 55),\n",
    "#          ensemble.RandomForestRegressor(max_depth= 9, max_features='sqrt', n_estimators= 220)),\n",
    "            (sl1,sl2),\n",
    "         y_col,'sl3.csv',drop=drop_col,columns=['id','E','Eg'],\n",
    "         new_column_names=['id','formation_energy_ev_natom' ,'bandgap_energy_ev'],change_col_names=True,fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_sl=[]\n",
    "for i,y in enumerate(y_col):\n",
    "    print(y)\n",
    "    y_train=df_total_train_eval[y].values\n",
    "    print(X_train.shape,y_train.shape)\n",
    "\n",
    "    grid=RandomizedSearchCV(model,param_distributions=params, n_iter=n_iter,cv=cv,verbose=verbose,scoring=\"neg_mean_squared_error\" )\n",
    "\n",
    "    grid.fit(X_train,y_train)\n",
    "    grids_sl.append(grid)\n",
    "\n",
    "    sls[i].fit(X_train, y_train)\n",
    "    preds = sls[i].predict(X_train)\n",
    "    print(rmse(y_train, preds))\n",
    "#    results.append(mlens.metrics.rmse(y_train, ensemble.predict(X_train)),\n",
    "#                          evl.summary['test_score_mean']['superlearner'],\n",
    "#                          evl.summary['test_score_std']['superlearner'],\n",
    "#                          mlens.metrics.rmse(y_test, ensemble.predict(X_test)))\n",
    "\n",
    "#    print_scores(scores_df, 'mlens')   X_train=df.drop(y_col+drop_col,axis=1).values\n",
    "    for y in y_col:\n",
    "\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#importance of each feature\n",
    "non_features = y_col+drop_col\n",
    "features = [col for col in list(df_total_train_eval) if col not in non_features]\n",
    "importances_E =  grids[0].best_estimator_.feature_importances_\n",
    "\n",
    "assert(len(importances_E)==len(features))\n",
    "\n",
    "descending_indices_E = np.argsort(importances_E)[::-1]\n",
    "sorted_importances_E = [importances_E[idx] for idx in descending_indices_E]\n",
    "sorted_features_E = [features[idx] for idx in descending_indices_E]\n",
    "print('most important feature for formation energy is %s' % sorted_features_E[0])\n",
    "for f, i in zip(sorted_features_E,sorted_importances_E):\n",
    "    print('E',f,i)\n",
    "    \n",
    "importances_Eg =  grids[1].best_estimator_.feature_importances_\n",
    "descending_indices_Eg = np.argsort(importances_Eg)[::-1]\n",
    "sorted_importances_Eg = [importances_Eg[idx] for idx in descending_indices_Eg]\n",
    "sorted_features_Eg = [features[idx] for idx in descending_indices_Eg]\n",
    "print('most important feature for band gap is %s' % sorted_features_Eg[0])\n",
    "\n",
    "\n",
    "    \n",
    "for f, i in zip(sorted_features_Eg,sorted_importances_Eg):\n",
    "    print('Eg',f,i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#write to csv\n",
    "%load_ext autoreload\n",
    "%aimport varie\n",
    "%autoreload 2\n",
    "#I use a different model for E and Eg\n",
    "varie.make_csv2(df_total_train_eval,pd.DataFrame(),df_total_test,\n",
    "#         (ensemble.RandomForestRegressor(max_depth= 11, max_features='log2', n_estimators= 55),\n",
    "#          ensemble.RandomForestRegressor(max_depth= 9, max_features='sqrt', n_estimators= 220)),\n",
    "            (grids[0].best_estimator_,grids[1].best_estimator_),\n",
    "         y_col,'rf2c.csv',drop=drop_col,columns=['id','E','Eg'],\n",
    "         new_column_names=['id','formation_energy_ev_natom' ,'bandgap_energy_ev'],change_col_names=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from  catboost import CatBoostRegressor\n",
    "def runCatBoost(x_train, y_train,x_test, y_test,test,depth):\n",
    "    model=CatBoostRegressor(iterations=1200,\n",
    "                            learning_rate=0.03,\n",
    "                            depth=depth,\n",
    "                            loss_function='RMSE',\n",
    "                            eval_metric='RMSE',\n",
    "                            random_seed=99,\n",
    "                            od_type='Iter',\n",
    "                            od_wait=50)\n",
    "    model.fit(x_train, y_train, eval_set=(x_test, y_test), use_best_model=True, verbose=False)\n",
    "    y_pred_train=model.predict(x_test)\n",
    "    rmsle_result = rmsle(np.exp(y_pred_train)-1,np.exp(y_test)-1)\n",
    "    y_pred_test=model.predict(test)\n",
    "    return y_pred_train,rmsle_result,y_pred_test\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# A host of Scikit-learn models\n",
    "from sklearn.svm import SVC, LinearSVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from catboost import CatBoostRegressor\n",
    "SEED=1\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    #nb = GaussianNB()\n",
    "    svc = SVR(C=100)\n",
    "    knn = KNeighborsRegressor(n_neighbors=3)\n",
    "    nn = MLPRegressor((80, 10), early_stopping=False, random_state=SEED)\n",
    "    gb = GradientBoostingRegressor(n_estimators=100, random_state=SEED)\n",
    "    rf = RandomForestRegressor(n_estimators=250, max_features='sqrt', max_depth=100, random_state=SEED)\n",
    "    cb= CatBoostRegressor(depth=4,iterations=1200,learning_rate=0.03,verbose=False)\n",
    "\n",
    "    models = {'svm': svc,\n",
    "              'knn': knn,\n",
    "              'mlp-nn': nn,\n",
    "              'random forest': rf,\n",
    "              'gbm': gb,\n",
    "              'catboost':cb\n",
    "              }\n",
    "\n",
    "    return models\n",
    "\n",
    "base_learners = get_models()\n",
    "\n",
    "\n",
    "#meta_learner = GradientBoostingRegressor(\n",
    "#    n_estimators=1000,\n",
    "#    loss=\"exponential\",\n",
    "#    max_features=4,\n",
    "#    max_depth=3,\n",
    "#    subsample=0.5,\n",
    "#    learning_rate=0.005, \n",
    "#    random_state=SEED\n",
    "#)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#ensemble = SuperLearner(folds=5, scorer=mse)\n",
    "#ensemble.add([xgb.XGBRegressor(), lgb.LGBMRegressor(n_estimators=30)])\n",
    "#ensemble.add_meta([LinearRegression()])\n",
    "\n",
    "evl = Evaluator(make_scorer(mlens.metrics.rmse), cv=5, shuffle=False)\n",
    "evl.fit(X_train, y_train, sl, {}, n_iter=1)\n",
    "\n",
    "\n",
    "scores_df['mlens'] = [mlens.metrics.rmse(y_train, ensemble.predict(X_train)),\n",
    "                      evl.summary['test_score_mean']['superlearner'],\n",
    "                      evl.summary['test_score_std']['superlearner'],\n",
    "                      mlens.metrics.rmse(y_test, ensemble.predict(X_test))]\n",
    "\n",
    "print_scores(scores_df, 'mlens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "evaluator.fit(X_train, y_train,sl)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for y in y_col:\n",
    "    print(y)\n",
    "    y_train=df_total_train_eval[y].values\n",
    "    y_test=df_total_test[y].values\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    \n",
    "\n",
    "    model=CatBoostRegressor(loss_function='RMSE', eval_metric='RMSE',verbose=False)\n",
    "    params= {\"depth\": scipy.stats.randint(1,5), \n",
    "             'iterations': scipy.stats.randint(1000,2000),\n",
    "             'learning_rate':lognuniform(low=-2,high=-1,base=10,size=100)}\n",
    "    \n",
    "    \n",
    "    grid=RandomizedSearchCV(sl,param_distributions=params, n_iter=20,cv=4,verbose=2,scoring=\"neg_mean_squared_error\" )\n",
    "\n",
    "                        \n",
    "    grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adb': (AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='square',\n",
       "           n_estimators=50, random_state=None),\n",
       "  {'learning_rate': <varie.loguniform at 0x7fefeceb89e8>,\n",
       "   'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefeceb8710>}),\n",
       " 'cb': (<catboost.core.CatBoostRegressor at 0x7fefece96828>,\n",
       "  {'depth': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefece96908>,\n",
       "   'iterations': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefece969e8>,\n",
       "   'learning_rate': <varie.loguniform at 0x7fefece96ba8>}),\n",
       " 'eln': (ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  {'alpha': <varie.loguniform at 0x7fefeceb81d0>,\n",
       "   'l1_ratio': <varie.loguniform at 0x7fefeceb8278>}),\n",
       " 'gb': (GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "               max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "               min_impurity_split=None, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=100, presort='auto', random_state=None,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       "  {'learning_rate': <varie.loguniform at 0x7fefece96e48>,\n",
       "   'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefece96f60>}),\n",
       " 'knn': (KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       "  {'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefed124240>}),\n",
       " 'lasso': (Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  {'alpha': <varie.loguniform at 0x7fefeceb8470>}),\n",
       " 'mlp': (MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(80, 10), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "         shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "         verbose=False, warm_start=False),\n",
       "  {'alpha': <varie.loguniform at 0x7fefece96e10>,\n",
       "   'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefece96cc0>}),\n",
       " 'rf': (RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=False,\n",
       "             warm_start=False),\n",
       "  {'max_depth': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefece964e0>,\n",
       "   'max_features': ('log2', 'sqrt', 'auto'),\n",
       "   'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefece96668>}),\n",
       " 'ridge': (Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "     normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  {'alpha': <varie.loguniform at 0x7fefeceb80f0>}),\n",
       " 'svr': (SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "  {'C': <varie.loguniform at 0x7fefece96748>,\n",
       "   'epsilon': <varie.loguniform at 0x7fefece964a8>}),\n",
       " 'xgb': (XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "         learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "         min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "         objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "         scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "  {'learning_rate': <varie.loguniform at 0x7fefeceb8438>,\n",
       "   'max_depth': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefeceb82e8>,\n",
       "   'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x7fefeceb87f0>})}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ests=[(tag, model[0]) for tag,model in models.items()]\n",
    "params={tag:model[1] for tag,model in models.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "(2400, 21) (2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of varie failed: Traceback (most recent call last):\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 626, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n",
      "  File \"../kaggle_varie/varie.py\", line 186, in <module>\n",
      "    class loguniform:\n",
      "  File \"../kaggle_varie/varie.py\", line 196, in loguniform\n",
      "    def rvs(size=size):\n",
      "NameError: name 'size' is not defined\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "rvs() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-64d8ba35084f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mevaluators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, estimators, param_dicts, n_iter, preprocessing)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \"\"\"\n\u001b[1;32m    505\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, job, estimators, preprocessing, param_dicts, n_iter)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_param_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             generator = [\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_draw_param_dicts\u001b[0;34m(self, param_dicts)\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0;31m# the expected param_dicts key is 'est_name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mest_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# Preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, param_dicts, key)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;31m# No param draws desired. Set empty dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_draw_params\u001b[0;34m(self, param_dists)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# Fill list of parameter settings by param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_dists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mdraws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: rvs() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "from mlens.model_selection import Evaluator\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Here we name the estimators ourselves\n",
    "#ests = [('gnb', GaussianNB()), ('knn', KNeighborsClassifier())]\n",
    "\n",
    "# Now we map parameters to these\n",
    "# The gnb doesn't have any parameters so we can skip it\n",
    "#pars = {'n_neighbors': randint(2, 20)}\n",
    "#params = {'knn': pars}\n",
    "\n",
    "evaluators=[]\n",
    "for i,y in enumerate(y_col):\n",
    "    print(y)\n",
    "    y_train=df_total_train_eval[y].values\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    evaluator = Evaluator(rmse_scorer, cv=10,  verbose=1)\n",
    "\n",
    "    \n",
    "    evaluator.fit(X_train,y_train, ests, params, n_iter=5)\n",
    "    evaluators.append(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlens.metrics import make_scorer\n",
    "rmse_scorer = make_scorer(rmse, average='micro', greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learners=[(tag,model[0]) for tag,model in models.items()]\n",
    "param_dicts_base={tag:model[1] for tag,model in models.items()}\n",
    "len(param_dicts_base),len(base_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "SEED=1\n",
    "# We consider the following models (or base learners)\n",
    "gb = XGBRegressor()\n",
    "ls = Lasso(alpha=1e-6, normalize=True)\n",
    "el = ElasticNet(alpha=1e-6, normalize=True)\n",
    "rf = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "base_learners = [\n",
    "    ('ls', ls), ('el', el), ('rf', rf), ('gb', gb)\n",
    "]\n",
    "\n",
    "# Put their parameter dictionaries in a dictionary with the\n",
    "# estimator names as keys\n",
    "param_dicts_base = {\n",
    "    'ls':\n",
    "    {'alpha': uniform(1e-6, 1e-5)},\n",
    "    'el':\n",
    "    {'alpha': uniform(1e-6, 1e-5),\n",
    "     'l1_ratio': uniform(0, 1)\n",
    "    },\n",
    "    'gb':\n",
    "    {'learning_rate': uniform(0.02, 0.04),\n",
    "     'colsample_bytree': uniform(0.55, 0.66),\n",
    "     'min_child_weight': randint(30, 60),\n",
    "     'max_depth': randint(3, 7),\n",
    "     'subsample': uniform(0.4, 0.2),\n",
    "     'n_estimators': randint(150, 200),\n",
    "     'colsample_bytree': uniform(0.6, 0.4),\n",
    "     'reg_lambda': uniform(1, 2),\n",
    "     'reg_alpha': uniform(1, 2),\n",
    "    },\n",
    "    'rf':\n",
    "    {'max_depth': randint(2, 5),\n",
    "     'min_samples_split': randint(5, 20),\n",
    "     'min_samples_leaf': randint(10, 20),\n",
    "     'n_estimators': randint(50, 100),\n",
    "     'max_features': uniform(0.6, 0.3)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job\n",
      "Preprocessing 2 preprocessing pipelines over 2 CV folds\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "Preprocessing done | 00:00:00\n",
      "Evaluating 8 models for 2 parameter draws over 2 preprocessing pipelines and 2 CV folds, totalling 32 fits\n"
     ]
    },
    {
     "ename": "JoblibIndexError",
     "evalue": "JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 41, 18, 919084), 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2CB284014A464058AFF9C38F92506A27']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 41, 18, 919084), 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2CB284014A464058AFF9C38F92506A27'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 41, 18, 919084), 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assert object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-252-e67f4ab0a071>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fefedb95b00, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fefecf3e5d0, file \"<ipython-input-252-e67f4ab0a071>\", line 16>\n        result = <ExecutionResult object at 7fefedb95b00, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fefecf3e5d0, file \"<ipython-input-252-e67f4ab0a071>\", line 16>, result=<ExecutionResult object at 7fefedb95b00, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fefecf3e5d0, file \"<ipython-input-252-e67f4ab0a071>\", line 16>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/scratch/baruselli/kaggle_nomad/<ipython-input-252-e67f4ab0a071> in <module>()\n     16 evl.fit(\n     17     X_train, y_train,\n     18     estimators=base_learners,\n     19     param_dicts=param_dicts_base,\n     20     preprocessing={'sc': [StandardScaler()], 'none': []},\n---> 21     n_iter=2  # bump this up to do a larger grid search\n     22 )\n     23 \n     24 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), estimators=[('ls', Lasso(alpha=1e-06, copy_X=True, fit_intercept=Tr...selection='cyclic', tol=0.0001, warm_start=False)), ('el', ElasticNet(alpha=1e-06, copy_X=True, fit_interce...selection='cyclic', tol=0.0001, warm_start=False)), ('rf', RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False)), ('gb', XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1))], param_dicts={'el': {'alpha': <scipy.stats._distn_infrastructure.rv_frozen object>, 'l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'gb': {'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>, 'reg_alpha': <scipy.stats._distn_infrastructure.rv_frozen object>, 'reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen object>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'ls': {'alpha': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'rf': {'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>}}, n_iter=2, preprocessing={'none': [], 'sc': [StandardScaler(copy=True, with_mean=True, with_std=True)]})\n    502             class instance with stored estimator evaluation results in\n    503             the ``results`` attribute.\n    504         \"\"\"\n    505         job = set_job(estimators, preprocessing)\n    506         self._initialize(job, estimators, preprocessing, param_dicts, n_iter)\n--> 507         self._fit(X, y, job)\n        self._fit = <bound method BaseEval._fit of <mlens.model_selection.model_selection.Evaluator object>>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        job = 'preprocess-evaluate'\n    508         self._get_results()\n    509         return self\n    510 \n    511     def _initialize(self, job, estimators, preprocessing, param_dicts, n_iter):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), job='preprocess-evaluate')\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n    179         with ParallelEvaluation(self.backend, self.n_jobs, verbose) as manager:\n--> 180             manager.process(self, job, X, y)\n        manager.process = <bound method ParallelEvaluation.process of <mlens.parallel.backend.ParallelEvaluation object>>\n        self = <mlens.model_selection.model_selection.Evaluator object>\n        job = 'preprocess-evaluate'\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181 \n    182     def collect(self, path, case):\n    183         \"\"\"Collect cache estimators\"\"\"\n    184         if case == 'transformers':\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelEvaluation object>, caller=<mlens.model_selection.model_selection.Evaluator object>, case='preprocess-evaluate', X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), path=None, **kwargs={})\n    832         with Parallel(n_jobs=self.n_jobs, temp_folder=tf, max_nbytes=None,\n    833                       mmap_mode='w+', verbose=self.verbose,\n    834                       backend=self.backend) as parallel:\n    835 \n    836             caller.indexer.fit(self.job.predict_in, self.job.y, self.job.job)\n--> 837             caller(parallel, self.job.args(**kwargs), case)\n        caller = <mlens.model_selection.model_selection.Evaluator object>\n        parallel = Parallel(n_jobs=-1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        case = 'preprocess-evaluate'\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in __call__(self=<mlens.model_selection.model_selection.Evaluator object>, parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}, case='preprocess-evaluate')\n    147         if 'evaluate' in case:\n    148             if self.verbose >= 2:\n    149                 safe_print(self._print_eval_start(), file=f)\n    150                 t1 = time()\n    151 \n--> 152             self._run('estimators', parallel, args)\n        self._run = <bound method BaseEval._run of <mlens.model_selection.model_selection.Evaluator object>>\n        parallel = Parallel(n_jobs=-1)\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    153             self.collect(args['dir'], 'estimators')\n    154 \n    155             if self.verbose >= 2:\n    156                 print_time(t1, '{:<13} done'.format('Evaluation'), file=f)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _run(self=<mlens.model_selection.model_selection.Evaluator object>, case='estimators', parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}})\n    169         else:\n    170             generator = self._learners\n    171             inp = 'main'\n    172 \n    173         parallel(delayed(subtask, not _threading)()\n--> 174                  for task in generator for subtask in task(args, inp))\n        generator = [EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0)]\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEval._run.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Fri Feb  9 14:41:19 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if not path:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=[('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>)])\n    332         path = path if path else self.path\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n--> 337         self._fit(transformers)\n        self._fit = <bound method SubLearner._fit of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = Pipeline(name='pipeline-22', pipeline=None, return_y=True)\n    338         self._predict(transformers)\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in _fit(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=Pipeline(name='pipeline-22', pipeline=None, return_y=True))\n    175         t0 = time()\n    176         if transformers:\n    177             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n    178 \n    179         # Fit estimator\n--> 180         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method BaseForest.fit of RandomForestRegr...se, random_state=1, verbose=0, warm_start=False)>\n        xtemp = array([[80.    ,  9.4012, 90.003 , ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        ytemp = array([0.18248821, 0.14314751, 0.19169416, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181         self.fit_time_ = time() - t0\n    182 \n    183     def _load_preprocess(self, path):\n    184         \"\"\"Load preprocessing pipeline\"\"\"\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False), X=array([[80.    ,  9.4012, 90.003 , ...,  0.    ,... 0.    ,  1.    ,  0.    ]],\n      dtype=float32), y=array([[0.18248821],\n       [0.14314751],\n      ...28  ],\n       [0.22840966],\n       [0.10750821]]), sample_weight=None)\n    311                 random_state.randint(MAX_INT, size=len(self.estimators_))\n    312 \n    313             trees = []\n    314             for i in range(n_more_estimators):\n    315                 tree = self._make_estimator(append=False,\n--> 316                                             random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    317                 trees.append(tree)\n    318 \n    319             # Parallel loop: we use the threading backend as the Cython code\n    320             # for fitting the trees is internally releasing the Python GIL\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py in _make_estimator(self=RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False), append=False, random_state=<mtrand.RandomState object>)\n    120         \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n    121 \n    122         Warning: This method should be used to properly instantiate new\n    123         sub-estimators.\n    124         \"\"\"\n--> 125         estimator = clone(self.base_estimator_)\n        estimator = undefined\n        self.base_estimator_ = DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best')\n    126         estimator.set_params(**dict((p, getattr(self, p))\n    127                                     for p in self.estimator_params))\n    128 \n    129         if random_state is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in clone(estimator=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), safe=True)\n     59     klass = estimator.__class__\n     60     new_object_params = estimator.get_params(deep=False)\n     61     for name, param in six.iteritems(new_object_params):\n     62         new_object_params[name] = clone(param, safe=False)\n     63     new_object = klass(**new_object_params)\n---> 64     params_set = new_object.get_params(deep=False)\n        params_set = undefined\n        new_object.get_params = <bound method BaseEstimator.get_params of Decisi...esort=False, random_state=None, splitter='best')>\n     65 \n     66     # quick sanity check of the parameters of the clone\n     67     for name in new_object_params:\n     68         param1 = new_object_params[name]\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Launch job\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mtransformers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, transformers)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Fit estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_time_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 316\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nIndexError                                         Fri Feb  9 14:41:19 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if not path:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=[('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>)])\n    332         path = path if path else self.path\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n--> 337         self._fit(transformers)\n        self._fit = <bound method SubLearner._fit of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = Pipeline(name='pipeline-22', pipeline=None, return_y=True)\n    338         self._predict(transformers)\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in _fit(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=Pipeline(name='pipeline-22', pipeline=None, return_y=True))\n    175         t0 = time()\n    176         if transformers:\n    177             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n    178 \n    179         # Fit estimator\n--> 180         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method BaseForest.fit of RandomForestRegr...se, random_state=1, verbose=0, warm_start=False)>\n        xtemp = array([[80.    ,  9.4012, 90.003 , ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        ytemp = array([0.18248821, 0.14314751, 0.19169416, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181         self.fit_time_ = time() - t0\n    182 \n    183     def _load_preprocess(self, path):\n    184         \"\"\"Load preprocessing pipeline\"\"\"\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False), X=array([[80.    ,  9.4012, 90.003 , ...,  0.    ,... 0.    ,  1.    ,  0.    ]],\n      dtype=float32), y=array([[0.18248821],\n       [0.14314751],\n      ...28  ],\n       [0.22840966],\n       [0.10750821]]), sample_weight=None)\n    311                 random_state.randint(MAX_INT, size=len(self.estimators_))\n    312 \n    313             trees = []\n    314             for i in range(n_more_estimators):\n    315                 tree = self._make_estimator(append=False,\n--> 316                                             random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    317                 trees.append(tree)\n    318 \n    319             # Parallel loop: we use the threading backend as the Cython code\n    320             # for fitting the trees is internally releasing the Python GIL\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py in _make_estimator(self=RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False), append=False, random_state=<mtrand.RandomState object>)\n    120         \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n    121 \n    122         Warning: This method should be used to properly instantiate new\n    123         sub-estimators.\n    124         \"\"\"\n--> 125         estimator = clone(self.base_estimator_)\n        estimator = undefined\n        self.base_estimator_ = DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best')\n    126         estimator.set_params(**dict((p, getattr(self, p))\n    127                                     for p in self.estimator_params))\n    128 \n    129         if random_state is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in clone(estimator=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), safe=True)\n     59     klass = estimator.__class__\n     60     new_object_params = estimator.get_params(deep=False)\n     61     for name, param in six.iteritems(new_object_params):\n     62         new_object_params[name] = clone(param, safe=False)\n     63     new_object = klass(**new_object_params)\n---> 64     params_set = new_object.get_params(deep=False)\n        params_set = undefined\n        new_object.get_params = <bound method BaseEstimator.get_params of Decisi...esort=False, random_state=None, splitter='best')>\n     65 \n     66     # quick sanity check of the parameters of the clone\n     67     for name in new_object_params:\n     68         param1 = new_object_params[name]\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-e67f4ab0a071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mparam_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dicts_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;31m# bump this up to do a larger grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, estimators, param_dicts, n_iter, preprocessing)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, job)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mParallelEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, caller, case, X, y, path, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mcaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parallel, args, case)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'estimators'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, case, parallel, args)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         parallel(delayed(subtask, not _threading)()\n\u001b[0;32m--> 174\u001b[0;31m                  for task in generator for subtask in task(args, inp))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m: JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff06864a420, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/scratch/baruselli/inst/intelpython35/lib/python...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/scratch/bar.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 41, 18, 919084), 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2CB284014A464058AFF9C38F92506A27']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 41, 18, 919084), 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2CB284014A464058AFF9C38F92506A27'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 9, 14, 41, 18, 919084), 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'session': '2CB284014A464058AFF9C38F92506A27', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'FD6098E4F7164D269274EEFB953FEED5', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.preprocessing import StandardScaler...2  # bump this up to do a larger grid search\\n)\\n\\n\\n', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assert object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-252-e67f4ab0a071>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fefedb95b00, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fefecf3e5d0, file \"<ipython-input-252-e67f4ab0a071>\", line 16>\n        result = <ExecutionResult object at 7fefedb95b00, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fefecf3e5d0, file \"<ipython-input-252-e67f4ab0a071>\", line 16>, result=<ExecutionResult object at 7fefedb95b00, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fefecf3e5d0, file \"<ipython-input-252-e67f4ab0a071>\", line 16>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'CatBoostRegressor': <class 'catboost.core.CatBoostRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda...import warnings\\nwarnings.filterwarnings(\"ignore\")', \"columns={'spacegroup' : 'sg',\\n                  ...x=True)\\n\\nlen(df_train),len(df_test),len(df_total)\", 'df_total.head()', 'df_total.tail()', \"#from https://www.kaggle.com/cbartel/random-fore...\\ndf_total['sg']=df_total['sg'].astype('category')\", 'df_total.head()', '#Encoding of cat features\\nimport sys \\nsys.path.a...\\nenc=pd.get_dummies(df_total,columns=cols_to_enc)', 'def grid_search_fct(model,params,df,y_col,n_iter...rain)\\n        grids.append(grid)\\n    return grids', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#grid search for random forest\\nimport scipy\\nfrom...grid.fit(X_train,y_train)\\n    #grids.append(grid)', '#best model and its performance\\n\\nfor tag,grids i...].best_score_)+np.sqrt(-grids[1].best_score_))/2)', 'for (tag,model) in  models.items():\\n    print(tag)', 'for (tag,model) in  models.items():\\n    if (tag not in results): print(tag)', \"try:\\n    results\\nexcept:\\n    print ('no') #results={}\", \"try:\\n    abc\\nexcept:\\n    print ('no') #results={}\", 'import pickle', \"import pickle\\nget_ipython().run_line_magic('pinfo', 'pickle.dump')\", \"import pickle\\npickle.dump(results,'results_100iter.pickle')\", 'import pickle\\npickle.dump(results,, open( \"results_100iter.pickle\", \"wb\" ))', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/scratch/baruselli/kaggle_nomad/<ipython-input-252-e67f4ab0a071> in <module>()\n     16 evl.fit(\n     17     X_train, y_train,\n     18     estimators=base_learners,\n     19     param_dicts=param_dicts_base,\n     20     preprocessing={'sc': [StandardScaler()], 'none': []},\n---> 21     n_iter=2  # bump this up to do a larger grid search\n     22 )\n     23 \n     24 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), estimators=[('ls', Lasso(alpha=1e-06, copy_X=True, fit_intercept=Tr...selection='cyclic', tol=0.0001, warm_start=False)), ('el', ElasticNet(alpha=1e-06, copy_X=True, fit_interce...selection='cyclic', tol=0.0001, warm_start=False)), ('rf', RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False)), ('gb', XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1))], param_dicts={'el': {'alpha': <scipy.stats._distn_infrastructure.rv_frozen object>, 'l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'gb': {'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>, 'reg_alpha': <scipy.stats._distn_infrastructure.rv_frozen object>, 'reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen object>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'ls': {'alpha': <scipy.stats._distn_infrastructure.rv_frozen object>}, 'rf': {'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>}}, n_iter=2, preprocessing={'none': [], 'sc': [StandardScaler(copy=True, with_mean=True, with_std=True)]})\n    502             class instance with stored estimator evaluation results in\n    503             the ``results`` attribute.\n    504         \"\"\"\n    505         job = set_job(estimators, preprocessing)\n    506         self._initialize(job, estimators, preprocessing, param_dicts, n_iter)\n--> 507         self._fit(X, y, job)\n        self._fit = <bound method BaseEval._fit of <mlens.model_selection.model_selection.Evaluator object>>\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n        job = 'preprocess-evaluate'\n    508         self._get_results()\n    509         return self\n    510 \n    511     def _initialize(self, job, estimators, preprocessing, param_dicts, n_iter):\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), job='preprocess-evaluate')\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n    179         with ParallelEvaluation(self.backend, self.n_jobs, verbose) as manager:\n--> 180             manager.process(self, job, X, y)\n        manager.process = <bound method ParallelEvaluation.process of <mlens.parallel.backend.ParallelEvaluation object>>\n        self = <mlens.model_selection.model_selection.Evaluator object>\n        job = 'preprocess-evaluate'\n        X = array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        y = array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181 \n    182     def collect(self, path, case):\n    183         \"\"\"Collect cache estimators\"\"\"\n    184         if case == 'transformers':\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelEvaluation object>, caller=<mlens.model_selection.model_selection.Evaluator object>, case='preprocess-evaluate', X=array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), y=array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821]), path=None, **kwargs={})\n    832         with Parallel(n_jobs=self.n_jobs, temp_folder=tf, max_nbytes=None,\n    833                       mmap_mode='w+', verbose=self.verbose,\n    834                       backend=self.backend) as parallel:\n    835 \n    836             caller.indexer.fit(self.job.predict_in, self.job.y, self.job.job)\n--> 837             caller(parallel, self.job.args(**kwargs), case)\n        caller = <mlens.model_selection.model_selection.Evaluator object>\n        parallel = Parallel(n_jobs=-1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        case = 'preprocess-evaluate'\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in __call__(self=<mlens.model_selection.model_selection.Evaluator object>, parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}, case='preprocess-evaluate')\n    147         if 'evaluate' in case:\n    148             if self.verbose >= 2:\n    149                 safe_print(self._print_eval_start(), file=f)\n    150                 t1 = time()\n    151 \n--> 152             self._run('estimators', parallel, args)\n        self._run = <bound method BaseEval._run of <mlens.model_selection.model_selection.Evaluator object>>\n        parallel = Parallel(n_jobs=-1)\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    153             self.collect(args['dir'], 'estimators')\n    154 \n    155             if self.verbose >= 2:\n    156                 print_time(t1, '{:<13} done'.format('Evaluation'), file=f)\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/model_selection/model_selection.py in _run(self=<mlens.model_selection.model_selection.Evaluator object>, case='estimators', parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}})\n    169         else:\n    170             generator = self._learners\n    171             inp = 'main'\n    172 \n    173         parallel(delayed(subtask, not _threading)()\n--> 174                  for task in generator for subtask in task(args, inp))\n        generator = [EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0), EvalLearner(attr='predict', backend='threading',...error, greater_is_better=False),\n      verbose=0)]\n        args = {'auxiliary': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}, 'dir': [('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('sc.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': None, 'X': array([[80.    ,  9.9523, 90.0026, ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]]), 'y': array([0.06578774, 0.22234323, 0.16729252, ..., 0.086728  , 0.22840966,\n       0.10750821])}}\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEval._run.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Fri Feb  9 14:41:19 2018\nPID: 13249   Python 3.5.2: /scratch/baruselli/inst/intelpython35/bin/python\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if not path:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=[('none.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('sc.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.1.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.el.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.gb.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.1', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.0.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.2', <mlens.parallel.learner.IndexedEstimator object>), ('none.ls.1.0.1', <mlens.parallel.learner.IndexedEstimator object>)])\n    332         path = path if path else self.path\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n--> 337         self._fit(transformers)\n        self._fit = <bound method SubLearner._fit of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = Pipeline(name='pipeline-22', pipeline=None, return_y=True)\n    338         self._predict(transformers)\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/mlens/parallel/learner.py in _fit(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=Pipeline(name='pipeline-22', pipeline=None, return_y=True))\n    175         t0 = time()\n    176         if transformers:\n    177             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n    178 \n    179         # Fit estimator\n--> 180         self.estimator.fit(xtemp, ytemp)\n        self.estimator.fit = <bound method BaseForest.fit of RandomForestRegr...se, random_state=1, verbose=0, warm_start=False)>\n        xtemp = array([[80.    ,  9.4012, 90.003 , ...,  0.    ,....0648, 90.0027, ...,  0.    ,  1.    ,  0.    ]])\n        ytemp = array([0.18248821, 0.14314751, 0.19169416, ..., 0.086728  , 0.22840966,\n       0.10750821])\n    181         self.fit_time_ = time() - t0\n    182 \n    183     def _load_preprocess(self, path):\n    184         \"\"\"Load preprocessing pipeline\"\"\"\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False), X=array([[80.    ,  9.4012, 90.003 , ...,  0.    ,... 0.    ,  1.    ,  0.    ]],\n      dtype=float32), y=array([[0.18248821],\n       [0.14314751],\n      ...28  ],\n       [0.22840966],\n       [0.10750821]]), sample_weight=None)\n    311                 random_state.randint(MAX_INT, size=len(self.estimators_))\n    312 \n    313             trees = []\n    314             for i in range(n_more_estimators):\n    315                 tree = self._make_estimator(append=False,\n--> 316                                             random_state=random_state)\n        random_state = <mtrand.RandomState object>\n    317                 trees.append(tree)\n    318 \n    319             # Parallel loop: we use the threading backend as the Cython code\n    320             # for fitting the trees is internally releasing the Python GIL\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/ensemble/base.py in _make_estimator(self=RandomForestRegressor(bootstrap=True, criterion=...lse, random_state=1, verbose=0, warm_start=False), append=False, random_state=<mtrand.RandomState object>)\n    120         \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n    121 \n    122         Warning: This method should be used to properly instantiate new\n    123         sub-estimators.\n    124         \"\"\"\n--> 125         estimator = clone(self.base_estimator_)\n        estimator = undefined\n        self.base_estimator_ = DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best')\n    126         estimator.set_params(**dict((p, getattr(self, p))\n    127                                     for p in self.estimator_params))\n    128 \n    129         if random_state is not None:\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in clone(estimator=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), safe=True)\n     59     klass = estimator.__class__\n     60     new_object_params = estimator.get_params(deep=False)\n     61     for name, param in six.iteritems(new_object_params):\n     62         new_object_params[name] = clone(param, safe=False)\n     63     new_object = klass(**new_object_params)\n---> 64     params_set = new_object.get_params(deep=False)\n        params_set = undefined\n        new_object.get_params = <bound method BaseEstimator.get_params of Decisi...esort=False, random_state=None, splitter='best')>\n     65 \n     66     # quick sanity check of the parameters of the clone\n     67     for name in new_object_params:\n     68         param1 = new_object_params[name]\n\n...........................................................................\n/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/sklearn/base.py in get_params(self=DecisionTreeRegressor(criterion='mse', max_depth...resort=False, random_state=None, splitter='best'), deep=False)\n    236                     value = getattr(self, key, None)\n    237                 if len(w) and w[0].category == DeprecationWarning:\n    238                     # if the parameter is deprecated, don't show it\n    239                     continue\n    240             finally:\n--> 241                 warnings.filters.pop(0)\n    242 \n    243             # XXX: should we rather test if instance of estimator?\n    244             if deep and hasattr(value, 'get_params'):\n    245                 deep_items = value.get_params().items()\n\nIndexError: pop from empty list\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlens.model_selection import Evaluator\n",
    "assert(len(base_learners)==len(param_dicts_base))\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "evl = Evaluator(\n",
    "    scorer,\n",
    "    cv=2,\n",
    "    random_state=SEED,\n",
    "    verbose=5,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "evl.fit(\n",
    "    X_train, y_train,\n",
    "    estimators=base_learners,\n",
    "    param_dicts=param_dicts_base,\n",
    "    preprocessing={'sc': [StandardScaler()], 'none': []},\n",
    "    n_iter=2  # bump this up to do a larger grid search\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score-m</th>\n",
       "      <th>test_score-s</th>\n",
       "      <th>train_score-m</th>\n",
       "      <th>train_score-s</th>\n",
       "      <th>pred_time-m</th>\n",
       "      <th>pred_time-s</th>\n",
       "      <th>fit_time-m</th>\n",
       "      <th>fit_time-s</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none.el</th>\n",
       "      <td>-0.090491</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.089310</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.036398</td>\n",
       "      <td>0.013003</td>\n",
       "      <td>{'alpha': 2.9216451067673484e-06, 'l1_ratio': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none.gb</th>\n",
       "      <td>-0.091834</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>-0.082747</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.015173</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.553889</td>\n",
       "      <td>0.053751</td>\n",
       "      <td>{'min_child_weight': 46, 'learning_rate': 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none.ls</th>\n",
       "      <td>-0.090211</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.088918</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>0.016091</td>\n",
       "      <td>0.087065</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>{'alpha': 2.655238783620573e-06}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none.rf</th>\n",
       "      <td>-0.101206</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>-0.093237</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.038409</td>\n",
       "      <td>0.020679</td>\n",
       "      <td>0.375930</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.62890412037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.el</th>\n",
       "      <td>-0.090415</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>-0.089112</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>{'alpha': 3.927727748163378e-06, 'l1_ratio': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.gb</th>\n",
       "      <td>-0.093977</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>-0.086887</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.474971</td>\n",
       "      <td>0.056973</td>\n",
       "      <td>{'min_child_weight': 32, 'learning_rate': 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.ls</th>\n",
       "      <td>-0.090822</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>-0.089476</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>{'alpha': 8.075902639540653e-06}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.rf</th>\n",
       "      <td>-0.115580</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>-0.109046</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.202402</td>\n",
       "      <td>0.026227</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.73818934364...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_score-m  test_score-s  train_score-m  train_score-s  \\\n",
       "none.el     -0.090491      0.003486      -0.089310       0.001786   \n",
       "none.gb     -0.091834      0.004192      -0.082747       0.001947   \n",
       "none.ls     -0.090211      0.003528      -0.088918       0.001773   \n",
       "none.rf     -0.101206      0.004496      -0.093237       0.001944   \n",
       "sc.el       -0.090415      0.003550      -0.089112       0.001791   \n",
       "sc.gb       -0.093977      0.004120      -0.086887       0.001693   \n",
       "sc.ls       -0.090822      0.003543      -0.089476       0.001828   \n",
       "sc.rf       -0.115580      0.007073      -0.109046       0.001947   \n",
       "\n",
       "         pred_time-m  pred_time-s  fit_time-m  fit_time-s  \\\n",
       "none.el     0.000214     0.000025    0.036398    0.013003   \n",
       "none.gb     0.015173     0.009527    0.553889    0.053751   \n",
       "none.ls     0.013295     0.016091    0.087065    0.015598   \n",
       "none.rf     0.038409     0.020679    0.375930    0.029805   \n",
       "sc.el       0.001874     0.002038    0.029383    0.010490   \n",
       "sc.gb       0.008305     0.004214    0.474971    0.056973   \n",
       "sc.ls       0.000239     0.000096    0.016792    0.003647   \n",
       "sc.rf       0.005519     0.000407    0.202402    0.026227   \n",
       "\n",
       "                                                    params  \n",
       "none.el  {'alpha': 2.9216451067673484e-06, 'l1_ratio': ...  \n",
       "none.gb  {'min_child_weight': 46, 'learning_rate': 0.04...  \n",
       "none.ls                   {'alpha': 2.655238783620573e-06}  \n",
       "none.rf  {'max_depth': 4, 'max_features': 0.62890412037...  \n",
       "sc.el    {'alpha': 3.927727748163378e-06, 'l1_ratio': 0...  \n",
       "sc.gb    {'min_child_weight': 32, 'learning_rate': 0.04...  \n",
       "sc.ls                     {'alpha': 8.075902639540653e-06}  \n",
       "sc.rf    {'max_depth': 3, 'max_features': 0.73818934364...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evl.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learners = [\n",
    "    ('gb', gb), ('el', el)\n",
    "]\n",
    "\n",
    "param_dicts = {\n",
    "    'el':\n",
    "    {'alpha': uniform(1e-5, 1),\n",
    "     'l1_ratio': uniform(0, 1)\n",
    "    },\n",
    "    'gb':\n",
    "    {'learning_rate': uniform(0.01, 0.2),\n",
    "     'subsample': uniform(0.5, 0.5),\n",
    "     'reg_lambda': uniform(0.1, 1),\n",
    "     'n_estimators': randint(10, 100)\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Put the layers you don't want to tune into an ensemble with model selection turned on\n",
    "# Just remember to turn it off when you're done!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_learners), len(param_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes from 2 to 3 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-7e61c402b72b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mparam_dicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#    preprocessing={'meta': preprocess},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m                           \u001b[0;31m# bump this up to do a larger grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() takes from 2 to 3 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "in_layer = SuperLearner(model_selection=True)\n",
    "in_layer.add(base_learners)\n",
    "\n",
    "preprocess = [in_layer]\n",
    "\n",
    "evl.fit(\n",
    "    X_train, y_train,\n",
    "    meta_learners,\n",
    "    param_dicts,\n",
    "#    preprocessing={'meta': preprocess},\n",
    "    n_iter=5                           # bump this up to do a larger grid search\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score-m</th>\n",
       "      <th>test_score-s</th>\n",
       "      <th>train_score-m</th>\n",
       "      <th>train_score-s</th>\n",
       "      <th>pred_time-m</th>\n",
       "      <th>pred_time-s</th>\n",
       "      <th>fit_time-m</th>\n",
       "      <th>fit_time-s</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meta.el</th>\n",
       "      <td>-0.023993</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.024774</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>1.328225</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>{'alpha': 0.00012437481734488664, 'l1_ratio': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.gb</th>\n",
       "      <td>-0.023334</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>-0.021284</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.248742</td>\n",
       "      <td>0.163684</td>\n",
       "      <td>1.312409</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>{'reg_lambda': 0.517022004702574, 'learning_ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_score-m  test_score-s  train_score-m  train_score-s  \\\n",
       "meta.el     -0.023993      0.000318      -0.024774       0.000724   \n",
       "meta.gb     -0.023334      0.000774      -0.021284       0.000475   \n",
       "\n",
       "         pred_time-m  pred_time-s  fit_time-m  fit_time-s  \\\n",
       "meta.el     0.002566     0.001773    1.328225    0.007859   \n",
       "meta.gb     0.248742     0.163684    1.312409    0.001766   \n",
       "\n",
       "                                                    params  \n",
       "meta.el  {'alpha': 0.00012437481734488664, 'l1_ratio': ...  \n",
       "meta.gb  {'reg_lambda': 0.517022004702574, 'learning_ra...  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evl.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognuniform(low=0, high=1, size=None, base=np.exp(1)):\n",
    "    return np.power(base, np.random.uniform(low, high, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.rvs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of varie failed: Traceback (most recent call last):\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/scratch/baruselli/inst/intelpython35/lib/python3.5/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 626, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 767, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 727, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n",
      "  File \"../kaggle_varie/varie.py\", line 190\n",
      "    def __init__(scipy.stats.uniform,low=0, high=1, size=None, base=10):\n",
      "                      ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "scipy.stats.uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.stats import *\n",
    "x = Symbol('x')\n",
    "X = ContinuousRV(x, 2*x, Interval(0, 1))\n",
    "\n",
    "P(X>.5) \n",
    "\n",
    "Var(X) # variance\n",
    "\n",
    "E(2*cos(X)+X**2) # complex expressions are ok too\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
